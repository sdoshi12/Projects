{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras   # Keras here\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# Some variables\n",
    "N_VALIDATION = 1000\n",
    "BATCH_SIZE = 64\n",
    "# Define training data function - LIST OF NIFTIS\n",
    "def get_training_data_datasets(shuffle=True):\n",
    "    \"\"\"\n",
    "    Provides training data in the form of <filenames> and <labels>.\n",
    "    Actual data are lazy-loaded at batch time.\n",
    "    \n",
    "    \n",
    "    Inputs:\n",
    "    shuffle: bool for whether to shuffle the niftis or not.\n",
    "    \n",
    "    Returns: \n",
    "    nii_files: A list of NIFTI files\n",
    "    nii_labels: A list of binary [0,1] labels corresponding to [rejected, accepted] respectively. \n",
    "    \"\"\"\n",
    "    \n",
    "    acc_file_loc = '/kundulab-data/dl-component-classification/meica_component_classification_experiment/dl_classify_mni/accepted/*nii.gz' #accepted file location with extension to find\n",
    "    acc_loc = '/kundulab-data/dl-component-classification/meica_component_classification_experiment/dl_classify_mni/accepted' #accepted file location with extension to find'\n",
    "\n",
    "    acc_filepaths = []\n",
    "    acc_nii = []\n",
    "\n",
    "    for i in glob.glob(acc_file_loc):\n",
    "        acc_filepaths.append(i)\n",
    "    for i in range(len(acc_filepaths)):\n",
    "        acc_nii.append(nib.load(os.path.join(acc_loc, acc_filepaths[i]))) #acc_nii is an array of all the accepted images nifti files\n",
    "\n",
    "    rej_file_loc = '/kundulab-data/dl-component-classification/meica_component_classification_experiment/dl_classify_mni/rejected/*nii.gz' #rej image location with extension to find\n",
    "    rej_loc = '/kundulab-data/dl-component-classification/meica_component_classification_experiment/dl_classify_mni/rejected' #no extension for path.join formatting\n",
    "\n",
    "    rej_filepaths = []\n",
    "    rej_nii = []\n",
    "\n",
    "    for i in glob.glob(rej_file_loc):\n",
    "        rej_filepaths.append(i)\n",
    "    for i in range(len(rej_filepaths)):\n",
    "        rej_nii.append(nib.load(os.path.join(rej_loc, rej_filepaths[i]))) #rej_nii is an array of all the accepted images nifti files    \n",
    "    \n",
    "    # Transform from 2 sets to 1 pair of data and labels\n",
    "    acc_labels = len(acc_nii)*[1]\n",
    "    rej_labels = len(rej_nii)*[0]\n",
    "    nii_files = acc_nii + rej_nii\n",
    "    nii_labels = acc_labels + rej_labels\n",
    "    \n",
    "    # Testing shuffle logic\n",
    "    # n_nifti_files = 1000\n",
    "    # idx_shuffle = np.arange(n_nifti_files)\n",
    "    # random.shuffle(idx_shuffle)\n",
    "    \n",
    "    # Skip this - its shuffling datasets, instead shuffle the slices of the datasets...\n",
    "    #n_nifti_files = len(nii_files)\n",
    "    #idx_shuffle = np.arange(n_nifti_files)\n",
    "    #random.shuffle(idx_shuffle)\n",
    "    #nii_files = nii_files[idx_shuffle]\n",
    "    #nii_labels = nii_labels[idx_shuffle]\n",
    "    \n",
    "    return nii_files, nii_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(shuffle=True):\n",
    "    \"\"\"\n",
    "    \n",
    "    SURAJ - pull the logic of LISTING nifti filename from above, and then BELOW IS THE SHUFFLING OPERATION\n",
    "    \n",
    "    Return a list of tuples of form (FILENAME, SLICE_NO)\n",
    "    So, from get_training_data_datasets() you get ->\n",
    "    \n",
    "    [\n",
    "     NIFTI_1\n",
    "     NIFTI_2\n",
    "     ...\n",
    "    ]\n",
    "    [\n",
    "     0\n",
    "     0\n",
    "     0\n",
    "     ...\n",
    "     1\n",
    "     1\n",
    "     1\n",
    "    ]\n",
    "    \n",
    "    Here, transform into:\n",
    "    \n",
    "    [\n",
    "     (NIFTI_1, 0, 0)\n",
    "     (NIFTI_1, 1, 0)    \n",
    "     (NIFTI_1, 2, 0)\n",
    "     ...\n",
    "     (NIFTI_1, 58, 0)\n",
    "     (NIFTI_2, 0, 0)\n",
    "     (NIFTI_2, 1, 0)    \n",
    "     (NIFTI_2, 2, 0)\n",
    "     ...\n",
    "     (NIFTI_2, 58, 0)\n",
    "     ...\n",
    "      \n",
    "     (NIFTI_1000, 0, 1)\n",
    "     (NIFTI_1000, 0, 1)\n",
    "     (NIFTI_1000, 1, 1)\n",
    "     (NIFTI_1000, 2, 1)\n",
    "     ...\n",
    "     (NIFTI_1000, 58, 1)\n",
    "    ]\n",
    "    \n",
    "    Then - shuffle that\n",
    "    [\n",
    "     (NIFTI_47, 20, 0)\n",
    "     (NIFTI_670, 4, 1)\n",
    "     ...\n",
    "    ]\n",
    "    \n",
    "    \"\"\"\n",
    "    files, labels = get_training_data_datasets()\n",
    "    tuple_array = []\n",
    "    i=0\n",
    "    for file in files:\n",
    "        for slice in range(58):\n",
    "            tuple_array.append([file, slice, labels[i]])\n",
    "        i+=1\n",
    "    random.shuffle(tuple_array)\n",
    "    \n",
    "    return tuple_array\n"
   ]
  },
{
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['file1', 1, 0],\n",
       " ['file1', 2, 0],\n",
       " ['file1', 3, 0],\n",
       " ['file1', 4, 0],\n",
       " ['file1', 5, 0],\n",
       " ['file2', 1, 1],\n",
       " ['file2', 2, 1],\n",
       " ['file2', 3, 1],\n",
       " ['file2', 4, 1],\n",
       " ['file2', 5, 1],\n",
       " ['file3', 1, 0],\n",
       " ['file3', 2, 0],\n",
       " ['file3', 3, 0],\n",
       " ['file3', 4, 0],\n",
       " ['file3', 5, 0],\n",
       " ['file4', 1, 1],\n",
       " ['file4', 2, 1],\n",
       " ['file4', 3, 1],\n",
       " ['file4', 4, 1],\n",
       " ['file4', 5, 1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = ['file1', 'file2', 'file3', 'file4']\n",
    "test2 = [1,2,3,4,5]\n",
    "test3 = [0,1,0,1]\n",
    "\n",
    "ls = []\n",
    "i = 0\n",
    "for file in test1:\n",
    "    for slice in test2:\n",
    "        ls.append([file, slice, test3[i]])\n",
    "    i+=1\n",
    "\n",
    "ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "def define_model():\n",
    "\t\"\"\"\n",
    "\t2-D convolutional neural network to define 2-D slices with 8-channels each\n",
    "\tActual data are lazy-loaded at batch time.\n",
    "\n",
    "\tReturns:\n",
    "\tmodel: A Keras model\n",
    "\t\"\"\"\n",
    "\tmodel = keras.Sequential()\n",
    "\tmodel.add(keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(72, 59, 8)))\n",
    "\tmodel.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\tmodel.add(keras.layers.Flatten())\n",
    "\tmodel.add(keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nii_slice_addresses_to_tf_dataframe(num_slices):\n",
    "    \"\"\"\n",
    "    Lazy-loading for batch time.\n",
    "    Pick 2-D slices to select randomly.\n",
    "    \n",
    "    Returns:\n",
    "    A tf dataframe loaded from nii_files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Suraj - complet this fcn\n",
    "    tuple_array = get_training_data()\n",
    "    \n",
    "    # sanity check to see if the tuples change \n",
    "    print(tuple_array[0])\n",
    "    \n",
    "    slices = []\n",
    "    val_slices=[]\n",
    "    for i in range(num_slices):\n",
    "        im_fdata = tuple_array[i][0].get_fdata()\n",
    "        slices.append(im_fdata[tuple_array[i][1]])\n",
    "        val_slices.append(im_fdata[tuple_array[i+num_slices][1]])\n",
    "    \n",
    "    target = [tuple_array[i][2] for i in range(num_slices)]\n",
    "    val_target = [tuple_array[i+num_slices][2] for i in range(num_slices)]\n",
    "    print(len(target))\n",
    "\n",
    "    # train_dataset = tf.data.Dataset.from_tensor_slices((slices, target))\n",
    "    # train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "    \n",
    "       \n",
    "    return slices, target, val_slices, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory_batch: 0\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02282d5290>, 24, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 296.6139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.4900\n",
      "Validation acc: 0.4300\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1186.3457\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.5250\n",
      "Validation acc: 0.4200\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 93.9575\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.5767\n",
      "Validation acc: 0.4733\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 108.0572\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.6200\n",
      "Validation acc: 0.5025\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 91.7024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.6320\n",
      "Validation acc: 0.5220\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 26.8319\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.6600\n",
      "Validation acc: 0.5333\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.0298\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.6957\n",
      "Validation acc: 0.5186\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.2484\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.7287\n",
      "Validation acc: 0.5088\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 4.0680\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.7522\n",
      "Validation acc: 0.5011\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 4.8840\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.7680\n",
      "Validation acc: 0.4950\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.0781\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.7855\n",
      "Validation acc: 0.4900\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.6097\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8025\n",
      "Validation acc: 0.4850\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3388\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8169\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1276\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8293\n",
      "Validation acc: 0.4771\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8407\n",
      "Validation acc: 0.4733\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8506\n",
      "Validation acc: 0.4706\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8594\n",
      "Validation acc: 0.4671\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8672\n",
      "Validation acc: 0.4639\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8742\n",
      "Validation acc: 0.4605\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8805\n",
      "Validation acc: 0.4575\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8862\n",
      "Validation acc: 0.4548\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8914\n",
      "Validation acc: 0.4518\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.8961\n",
      "Validation acc: 0.4483\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9004\n",
      "Validation acc: 0.4450\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9044\n",
      "Validation acc: 0.4420\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9081\n",
      "Validation acc: 0.4392\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9115\n",
      "Validation acc: 0.4367\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9146\n",
      "Validation acc: 0.4343\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9176\n",
      "Validation acc: 0.4324\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9203\n",
      "Validation acc: 0.4307\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9229\n",
      "Validation acc: 0.4294\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9253\n",
      "Validation acc: 0.4281\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9276\n",
      "Validation acc: 0.4273\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9297\n",
      "Validation acc: 0.4265\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9317\n",
      "Validation acc: 0.4263\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9336\n",
      "Validation acc: 0.4261\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9354\n",
      "Validation acc: 0.4262\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9371\n",
      "Validation acc: 0.4263\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9387\n",
      "Validation acc: 0.4264\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9402\n",
      "Validation acc: 0.4265\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9417\n",
      "Validation acc: 0.4266\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9431\n",
      "Validation acc: 0.4267\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9444\n",
      "Validation acc: 0.4267\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9457\n",
      "Validation acc: 0.4268\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9469\n",
      "Validation acc: 0.4269\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9480\n",
      "Validation acc: 0.4270\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9491\n",
      "Validation acc: 0.4270\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9502\n",
      "Validation acc: 0.4271\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9512\n",
      "Validation acc: 0.4271\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9522\n",
      "Validation acc: 0.4272\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9531\n",
      "Validation acc: 0.4273\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9540\n",
      "Validation acc: 0.4273\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9549\n",
      "Validation acc: 0.4274\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9557\n",
      "Validation acc: 0.4274\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9565\n",
      "Validation acc: 0.4275\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9573\n",
      "Validation acc: 0.4275\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9581\n",
      "Validation acc: 0.4275\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9588\n",
      "Validation acc: 0.4276\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9595\n",
      "Validation acc: 0.4276\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9602\n",
      "Validation acc: 0.4277\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9608\n",
      "Validation acc: 0.4277\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9615\n",
      "Validation acc: 0.4277\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9621\n",
      "Validation acc: 0.4278\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9627\n",
      "Validation acc: 0.4278\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9632\n",
      "Validation acc: 0.4278\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9638\n",
      "Validation acc: 0.4279\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9643\n",
      "Validation acc: 0.4279\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9649\n",
      "Validation acc: 0.4279\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9654\n",
      "Validation acc: 0.4280\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9659\n",
      "Validation acc: 0.4280\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9663\n",
      "Validation acc: 0.4280\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9668\n",
      "Validation acc: 0.4281\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9673\n",
      "Validation acc: 0.4281\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9677\n",
      "Validation acc: 0.4281\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9681\n",
      "Validation acc: 0.4281\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9686\n",
      "Validation acc: 0.4282\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9690\n",
      "Validation acc: 0.4282\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9694\n",
      "Validation acc: 0.4282\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9697\n",
      "Validation acc: 0.4282\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9701\n",
      "Validation acc: 0.4283\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9705\n",
      "Validation acc: 0.4283\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9709\n",
      "Validation acc: 0.4283\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9712\n",
      "Validation acc: 0.4283\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4283\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9719\n",
      "Validation acc: 0.4284\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9722\n",
      "Validation acc: 0.4284\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4284\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4284\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4284\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4284\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4285\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4285\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4285\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4285\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4285\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4285\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4286\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4286\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4286\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4286\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory_batch: 1\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f029c3dc590>, 46, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 642.1520\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9709\n",
      "Validation acc: 0.4289\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 138.1459\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9676\n",
      "Validation acc: 0.4297\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.1269\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9661\n",
      "Validation acc: 0.4305\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 4.2744\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9655\n",
      "Validation acc: 0.4310\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.4884\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9650\n",
      "Validation acc: 0.4318\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5268\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9651\n",
      "Validation acc: 0.4329\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2148\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9652\n",
      "Validation acc: 0.4341\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0572\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9655\n",
      "Validation acc: 0.4349\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0433\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9656\n",
      "Validation acc: 0.4355\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0259\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9657\n",
      "Validation acc: 0.4361\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0037\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9660\n",
      "Validation acc: 0.4368\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0940\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9663\n",
      "Validation acc: 0.4374\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0035\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9665\n",
      "Validation acc: 0.4381\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.6652\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9667\n",
      "Validation acc: 0.4386\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2225\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9668\n",
      "Validation acc: 0.4390\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0546\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9670\n",
      "Validation acc: 0.4393\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8872\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9672\n",
      "Validation acc: 0.4399\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0027\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9675\n",
      "Validation acc: 0.4405\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0580\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9676\n",
      "Validation acc: 0.4413\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9679\n",
      "Validation acc: 0.4419\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9682\n",
      "Validation acc: 0.4426\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9684\n",
      "Validation acc: 0.4432\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1155\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9686\n",
      "Validation acc: 0.4437\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0187\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9688\n",
      "Validation acc: 0.4442\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0727\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9690\n",
      "Validation acc: 0.4447\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9692\n",
      "Validation acc: 0.4452\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9694\n",
      "Validation acc: 0.4457\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1286\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9695\n",
      "Validation acc: 0.4461\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9698\n",
      "Validation acc: 0.4466\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9700\n",
      "Validation acc: 0.4471\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9702\n",
      "Validation acc: 0.4476\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9705\n",
      "Validation acc: 0.4480\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9707\n",
      "Validation acc: 0.4483\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9709\n",
      "Validation acc: 0.4488\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9711\n",
      "Validation acc: 0.4492\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4496\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4501\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9717\n",
      "Validation acc: 0.4507\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9719\n",
      "Validation acc: 0.4512\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9721\n",
      "Validation acc: 0.4517\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0022\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9723\n",
      "Validation acc: 0.4523\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0022\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4530\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0021\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4536\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0021\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4541\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4546\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9733\n",
      "Validation acc: 0.4551\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0019\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4556\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0019\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4561\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0019\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4566\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0018\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4571\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0018\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4576\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4581\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4586\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4590\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4595\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4599\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4604\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4608\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4613\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4617\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4621\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4625\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4629\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4632\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4636\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4639\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4643\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4646\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4649\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4652\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4656\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4659\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4662\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4665\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4668\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4671\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4674\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4677\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4680\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4683\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4686\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4688\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4691\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4697\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4699\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4702\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4705\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4707\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4710\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4713\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4715\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9798\n",
      "Validation acc: 0.4718\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9799\n",
      "Validation acc: 0.4720\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9800\n",
      "Validation acc: 0.4723\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9801\n",
      "Validation acc: 0.4725\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9802\n",
      "Validation acc: 0.4727\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9803\n",
      "Validation acc: 0.4730\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9804\n",
      "Validation acc: 0.4732\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9805\n",
      "Validation acc: 0.4735\n",
      "Memory_batch: 2\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02f80c0210>, 23, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 479.6502\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4741\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 132.2912\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4745\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 51.6510\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4749\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 9.8700\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4752\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 10.7127\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4755\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.6546\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4756\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.1666\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9730\n",
      "Validation acc: 0.4758\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5993\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4760\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0271\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4761\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8655\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4763\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0383\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4765\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0876\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4767\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2616\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4770\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1703\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4773\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0198\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4776\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0187\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0178\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4781\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0167\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9730\n",
      "Validation acc: 0.4783\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0162\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4786\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0222\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4788\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0148\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4790\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0142\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9733\n",
      "Validation acc: 0.4793\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4795\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0130\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4797\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0124\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4800\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0120\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4803\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0116\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4805\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0111\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0107\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0103\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0100\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0098\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0096\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0093\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0088\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4841\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0088\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4843\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0087\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4845\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0087\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4847\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0086\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4848\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0086\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4850\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0086\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4852\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4854\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4856\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4857\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0084\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4859\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0084\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4861\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0084\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4863\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0084\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4864\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0083\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4866\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0083\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4868\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0083\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4869\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0083\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4871\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4873\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4878\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4879\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0081\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4881\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0081\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0081\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4884\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0081\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4885\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0081\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4887\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4889\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4890\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4892\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4893\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4895\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4896\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4897\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4899\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4900\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4902\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4903\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4905\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4906\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4907\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4909\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4910\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4912\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4913\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4914\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4916\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4917\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4918\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4920\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4921\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4922\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4923\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4925\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4926\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4927\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4928\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4930\n",
      "Memory_batch: 3\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02496ad890>, 5, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 470.8694\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4931\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 153.8942\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4931\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 57.9282\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4932\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 20.3467\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4933\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.3838\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9723\n",
      "Validation acc: 0.4933\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.1407\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9720\n",
      "Validation acc: 0.4933\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 4.5687\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9717\n",
      "Validation acc: 0.4933\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.9289\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4932\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8460\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4932\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1606\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4930\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0702\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4928\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0975\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4926\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1719\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9712\n",
      "Validation acc: 0.4924\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0145\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4921\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0155\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4918\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0200\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9713\n",
      "Validation acc: 0.4915\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0224\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4913\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0165\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4910\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0173\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4908\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2159\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4905\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0272\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4902\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0176\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4899\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0142\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9714\n",
      "Validation acc: 0.4896\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0141\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4894\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4891\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4888\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9715\n",
      "Validation acc: 0.4885\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9716\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9716\n",
      "Validation acc: 0.4879\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9716\n",
      "Validation acc: 0.4875\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9716\n",
      "Validation acc: 0.4872\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9717\n",
      "Validation acc: 0.4869\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9717\n",
      "Validation acc: 0.4866\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9717\n",
      "Validation acc: 0.4863\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9717\n",
      "Validation acc: 0.4861\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9718\n",
      "Validation acc: 0.4858\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0140\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9718\n",
      "Validation acc: 0.4855\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9719\n",
      "Validation acc: 0.4852\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9719\n",
      "Validation acc: 0.4849\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9720\n",
      "Validation acc: 0.4846\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9721\n",
      "Validation acc: 0.4844\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9721\n",
      "Validation acc: 0.4841\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9722\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9722\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9723\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9723\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0138\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4806\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4804\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9730\n",
      "Validation acc: 0.4799\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4796\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4794\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4791\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9733\n",
      "Validation acc: 0.4789\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4787\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4784\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4782\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0137\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4772\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4770\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4767\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4765\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4763\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4760\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4758\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4756\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4754\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4751\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4749\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4747\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4745\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4742\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4740\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4738\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4736\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4734\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4732\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4729\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4727\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4725\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4723\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4721\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0135\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4719\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4717\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4715\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4713\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4711\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4709\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4707\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4705\n",
      "Memory_batch: 4\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7efc64cdc510>, 12, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 493.0890\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4706\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 178.1177\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4707\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 27.1564\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4707\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 7.4819\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4706\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 4.5414\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4704\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.4101\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4703\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5789\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4702\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1653\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4700\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1994\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4699\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0150\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4698\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0322\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9724\n",
      "Validation acc: 0.4697\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0169\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4697\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0157\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4696\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0166\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4695\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0191\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4695\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2132\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1964\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0205\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4693\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0275\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4693\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0390\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4693\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1050\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4693\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0679\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0344\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9725\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0248\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0213\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9726\n",
      "Validation acc: 0.4694\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0193\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4695\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0180\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4695\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0172\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9727\n",
      "Validation acc: 0.4695\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0164\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4696\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0156\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9728\n",
      "Validation acc: 0.4696\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0149\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4697\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0141\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4697\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9729\n",
      "Validation acc: 0.4697\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0127\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9730\n",
      "Validation acc: 0.4698\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0120\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9730\n",
      "Validation acc: 0.4698\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0118\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4699\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0109\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4699\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0104\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4700\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0099\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4700\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0094\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4701\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9732\n",
      "Validation acc: 0.4701\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0086\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9733\n",
      "Validation acc: 0.4702\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9733\n",
      "Validation acc: 0.4702\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4702\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0075\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4703\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0072\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4703\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0069\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4704\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0067\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4704\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0064\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4705\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0062\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4705\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0060\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4706\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0058\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4706\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0056\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4706\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0055\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4707\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0053\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4707\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0052\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4708\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0050\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4708\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0049\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4709\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0048\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4709\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0046\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4709\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4710\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4710\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4711\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4711\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0041\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4711\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0040\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4712\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0039\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4712\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0038\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4713\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0037\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4713\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0037\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4713\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4714\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0035\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4714\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0034\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4715\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0034\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4715\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0033\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4715\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0032\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4716\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0032\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4716\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0031\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4717\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0030\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4717\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0030\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4717\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0029\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4718\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0029\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4718\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0028\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4718\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0028\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4719\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0028\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4719\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0027\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4720\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0027\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4720\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0027\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4720\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4721\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4721\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4721\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4722\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4722\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4722\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4723\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4723\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4724\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4724\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4724\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4725\n",
      "Memory_batch: 5\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f0249768510>, 55, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 822.0151\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4726\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 368.8390\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4727\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 80.8039\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4728\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 13.1604\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4728\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.1598\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4730\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.5119\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4732\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.9624\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4734\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 4.2059\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4735\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.0660\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4737\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.7032\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4738\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4902\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4740\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2813\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4741\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0096\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4743\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0755\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4745\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0074\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4746\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.3850\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9734\n",
      "Validation acc: 0.4748\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0056\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9735\n",
      "Validation acc: 0.4750\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0048\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4751\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0416\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4752\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0836\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4753\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1120\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9736\n",
      "Validation acc: 0.4754\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0075\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4755\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0028\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9737\n",
      "Validation acc: 0.4756\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4757\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.4758\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4759\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0019\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9739\n",
      "Validation acc: 0.4760\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4761\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9740\n",
      "Validation acc: 0.4762\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4763\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9741\n",
      "Validation acc: 0.4764\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4765\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9742\n",
      "Validation acc: 0.4766\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4767\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9743\n",
      "Validation acc: 0.4769\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4770\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9744\n",
      "Validation acc: 0.4771\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4772\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9745\n",
      "Validation acc: 0.4773\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9746\n",
      "Validation acc: 0.4775\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4776\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9747\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4778\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9748\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4780\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9749\n",
      "Validation acc: 0.4781\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4782\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9750\n",
      "Validation acc: 0.4783\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4784\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9751\n",
      "Validation acc: 0.4785\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4786\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4787\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4788\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4789\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4790\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4791\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4792\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4793\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4793\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4794\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4795\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4796\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4797\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4798\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4799\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4800\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4802\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4803\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4804\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4805\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4806\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4807\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4807\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4826\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD7CAYAAAASJLr7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR1UlEQVR4nO3dXYxc5XkH8P9/Z9def2D8EeK4tmVbghD5ojGtCyRU/cC4dUkKqIoQNIqiCmlvSAVKpEB61UqNlNwk4SJFQoHUFzRASEgRiqDIcVq1ao3NR9JgQ9gYXNv1B2Av/sD2emaeXMzxvM/szvGe2Xl2dmfm/5OQ3zlz5pwzrB+fZ9/zvu9DM4OIxBiY7QsQ6SUKKJFACiiRQAookUAKKJFACiiRQG0FFMltJN8kOUrywaiLEulWnO5zKJIlAL8GsBXAIQC7AdxtZnvjLk+kuwy28dnrAYya2X4AIPkEgNsB5AbUPM63YSxq45Qis+88zmLcLrDZe+0E1GoAB93rQwBuuNwHhrEIN3BLG6cUmX27bEfue+0EVCEkRwCMAMAwFs706URmVTudEocBrHWv12TbGpjZI2a22cw2D2F+G6cTmfvaCajdAK4huYHkPAB3AXg25rJEutO0Uz4zK5P8EoAXAJQAPGZmr4ddmUgXaut3KDP7KYCfBl2LSNfTSAmRQAookUAKKJFACiiRQAookUAKKJFACiiRQAookUAKKJFACiiRQAookUAKKJFACiiRQAookUAKKJFACiiRQAookUAKKJFACiiRQAookUAKKJFAUwYUycdIHif5K7dtOckXSb6V/blsZi9TpDsUuUP9M4BtE7Y9CGCHmV0DYEf2WqTvTRlQZvYfAE5M2Hw7gO1ZezuAO2IvS6Q7Tfd3qJVmdiRrHwWwMuh6RLpa250SVqvYllu1jeQIyT0k91zEhXZPJzKnTTegjpFcBQDZn8fzdlT1Dekn0w2oZwF8MWt/EcC/xlyOSHcr0m3+AwD/DeBakodI3gPgGwC2knwLwC3Za5G+N2X1DTO7O+ct1fYUmUAjJUQCKaBEAimgRAIpoEQCKaBEAimgRAIpoEQCKaBEAimgRAIpoEQCKaBEAimgRAIpoEQCKaBEAimgRAIpoEQCKaBEAimgRAIpoEQCKaBEAimgRAIpoEQCFVmXby3JnST3knyd5H3ZdpW0EZmgyB2qDOArZrYRwI0A7iW5ESppIzJJkXI2R8zslax9GsA+AKuhkjYik0y5cqxHcj2A6wDsQsGSNiRHAIwAwDAWTvtCRbpB4U4JkosB/AjA/WZ2yr93uZI2qr4h/aRQQJEcQi2YHjezH2ebC5e0EekXRXr5COBRAPvM7FvuLZW0EZmgyO9QNwH4AoD/Jflatu3vUCth81RW3uYAgDtn5ApFukiRcjb/CYA5b6ukjYijkRIigRRQIoFaeg4lc9BAKbWrlWkfhkPz6m27ON7OFfU13aFEAimgRAIp5ZsJdJ2izPk3q8X0jPPdKJNqGpRSKD1zaeHgqjRCzBYO19uV0bfr7XN3XF9vL/jJSy1dZ7/THUokkAJKJJBSvpnWTs+bS/M4mH5U1XPnWzpOafGievvs766utwcuVuvtee8cqrcrQyllHd/2B2mf53c3Pf7AwjSLoPrhhy1dW6/RHUokkAJKJJBSviA+JbNyuel2nxphyO0/fjG1z19I7QupjUpKHTnkf2zu+C61q7x/ot6uuuMMnU7nQimldhxO6eXiH+5Ku3xkRTommqu6a+53ukOJBFJAiQRSyjcD8sbFmUvbBhal9I/D6QGruYfCFf9Zl0b69K+0YnnT4zSkai79G/ivX6T24sXpsy41LS1LK8LZhfGm2ysnT6braaMns9foDiUSSAElEkgpXxQ3Zm9g/Zq0/eQH9Wblvffr7erZs2l/l6pxwYJ6u7T0yvTZDxoWmqqzM+k41bF0rtKqj6X2xo+nDxx9Nx3TpYLe4IZ16fhXup7D1/amfT6WxgSeviHtv+iFX6brOd/aA+heoDuUSCAFlEggpXxF+OkYZk23s5T+beJF1yN3RepJw4mx1HY9Yz41oju+f1Dre/Mq7jh5aVXlaFomkSeG0uW73kL/oJkLUtpZfvtAOpCfEeyYu86TH09/jRb/u5tmopRvMpLDJF8i+Yus+sY/ZNs3kNxFcpTkkyTnTXUskV5XJOW7AOBmM/skgE0AtpG8EcA3AXzbzK4GcBLAPTN2lSJdosi6fAbgTPZyKPvPANwM4K+z7dsB/D2Ah+MvcQ6wpsu2N+7iUqnygYPpDT9jt8ADUBtPD1IrJ92YQD9+L+c4DQ+U3cNfO5szq3fIJxU56VnOuSrHUkq59rFy0336UdG1zUvZqrHHAbwI4DcAxszs0v/JQ6iVuGn22RGSe0juuQgNopTeViigzKxiZpsArAFwPYBPFD2Bqm9IP2mpl8/MxkjuBPApAEtJDmZ3qTUADs/EBc6ovN67iVxPlx+D58fUme/ZM9/OSfP8MeelXjgMuR45l/41jN9bsqTpPq0+SG0YZ9jGWnx2Ns3S9dNA+nGtvyK9fFeRXJq1FwDYiloVw50APpftpuobIih2h1oFYDvJEmoB+JSZPUdyL4AnSP4jgFdRK3kj0teK9PL9ErUyoBO370ft96muxVJKu8ytdTexZ8v3sPmHrVZ2+7mxeV5eqlNavjQdf8kVzS/QpZHlg24RlVPNx/U1KJrOTnWYnJnI/vgDy5amfXyaOpBXtKV3aeiRSCAFlEigvh7L5x9+5i6ZjMbFUspHjk59YD/+LWcsXEMqdSLNfq24KRg+rTp+76fr7QXvp/X0ljy9Jx3Hf5+8NM+najlj+aqnz9TbDQvF5KSR5WNpSojvBW1I/4JS0LlOdyiRQAookUB9nfI1pB55D2Cno+rX0HMPN8tpTbzy0WNTH8dd30cfTmvl+eP75KmhQocz4Jd0dr2L9sHpetvPJvZpqk9NGy7N9/hZSkF9msd57rtf6I9hZ7pDiQRSQIkE6u+UbxoaFlTxKY1LgXwFCv9g9/xfpufgH2xI/+uXv5H2Gf6fX9fbDQ9w/cNm33Po0i2Pfn0/fxzf9j1+fm3Ahge46d/chl5Edw2lJWlWckMvZR/SHUokkAJKJJBSvlZdvT61XdWJ6v7/a7q7f3h68M9TirX/r/6p3t6y97Z6u3JL83F6A4vSGEI/BtGnc74nrdCjU9/LWSo13d44LaXadJ/KqfQguN/pDiUSSAElEojWwXFVS7jcbuCWjp2vk/wD3AH38NQvZlJIXg+eX6/P9zS66SSefXgutcdzqnh4fqxdgYVl/DVUXcE4n46WVl5Vb1fcg+zca+gSu2wHTtmJpnNTdIcSCaSAEgmkXr6MT9kmPiwtkqL4B7g+zcurrNFQsMxfh5vlauXm6bhfCAUrUhE0uuJoDSlftfny0Y1jGVO7dKVbPrrqe/NSjyLXuQojb466c6UUsXyo+9btaZfuUCKBFFAigZTyZfzUikkzSl2aNLhubb1dWZYWVymdSOmQX4q5Ya083/a9eX46RpH00vWqDZx1qZ1L+arnzrkPTN2T66d+0BV6Q8Wlv6fTdA+eSeMVvdLVG9JHR9+e8ry9pvAdKluO+VWSz2WvVX1DZIJWUr77UFvg8hJV3xCZoFDKR3INgM8A+DqAL7M2N6C3qm9cLi3yUxhcTduBRanXrro09YwNln+n3i4fcTNz/UPSApU48nrk/PSQhqJvbv3AVmfL+gey8L2Fbrxiw8Ish/+/6XGO/3Gq7btCKV+u7wD4KoBLCfUKFKy+IdJPiqxt/lkAx83s5emcQOVspJ8USfluAnAbyVsBDANYAuAhFKy+YWaPAHgEqI3lC7nqTnPpmV/MhH52qkuZyn7Kg0/tWhwvl1fPt+HScpaAzts/b5+GKh4nx1Lb9Sh6/oG1rxiy4vsvTX3eHjblHcrMvmZma8xsPYC7APzMzD4PVd8QmaSdB7sPoNZBMYra71SqviF9r9WCaz8H8POs3fXVNwrLSZ8aHsIWmZJwmeWepzLgxgGimh625hZZc+fioKsy0rBcs1tPz11/oYfLfjrJfPcI0j387UcaeiQSSAElEkhj+Vrl07ZWl28u8jC34Vwu1XS9iAO+QNuYO7x7gFtalsbj+WkjdiYtqNKwuIo1743koKv562vyunNV+mSZ5SJ0hxIJpIASCaSUr4iZqtLRTN4iLRfTA1bz7YYqGG68nx9z6Hr2qudcr2CBB8p5NYKlOd2hRAIpoEQCKeVrR1DdWF/UzE+78NM0cmf+5lAv3OzQHUokkAJKJJBSvnYELWPdMLv24vSXKR64Ij3w9WlkZWws7dTBpbf7ke5QIoEUUCKBlPLNAS1Xx/DLJl+VKlxU161M+4y74/iUT2aU7lAigRRQIoGU8s0BhQqQ5fTOmZshay+/53ZXb95s0B1KJJACSiSQUr5u4WfR+vF+Bcb1SecUXdv8HQCnAVQAlM1sM8nlAJ4EsB7AOwDuNLPmZflE+kQrKd+fmtkmM9ucvX4QwA4zuwbAjuy1SF9rJ+W7HcCfZO3tqK3X90Cb1yM5fJo3sHBhvV2tanbtXFL0DmUA/o3kyyRHsm0rzexI1j4KYGXzj4r0j6J3qD80s8MkPwrgRZJv+DfNzEg2ffCRBeAIAAxjYbNdRHpGoYAys8PZn8dJPoPaEszHSK4ysyMkVwE4nvPZ7q++MQdoBm53KFIfahHJKy61AfwZgF8BeBa1qhuAqm+IACh2h1oJ4JlaFVAMAvgXM3ue5G4AT5G8B8ABAHfO3GWKdIcpAyqrsvHJJtvfB7BlJi5KpFtp6JFIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEigQgFFcinJp0m+QXIfyU+RXE7yRZJvZX8um+mLFZnrit6hHgLwvJl9ArUlxfZB1TdEJimycuyVAP4IwKMAYGbjZjaGWvWN7dlu2wHcMTOXKNI9ityhNgB4F8D3Sb5K8nvZksyqviEyQZGAGgTwewAeNrPrAJzFhPTOaiXHc6tvkNxDcs9FaJF76W1FAuoQgENmtit7/TRqAXYsq7qBqapvmNlmM9s8hPkR1ywyZ00ZUGZ2FMBBktdmm7YA2AtV3xCZpGjBtb8F8DjJeQD2A/gb1IJR1TdEnKIF114DsLnJW6q+IeJopIRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIIAWUSCAFlEggBZRIoCLFAq4l+Zr77xTJ+1XORmSyIivHvmlmm8xsE4DfB/AhgGegcjYik7Sa8m0B8BszOwCVsxGZpOhSzJfcBeAHWbtQORuSIwBGAGAYC6dzjSJdo/AdKlvX/DYAP5z43uXK2aj6hvSTVlK+vwDwipkdy14XKmcj0k9aCai7kdI9QOVsRCYpWgV+EYCtAH7sNn8DwFaSbwG4JXst0tdY+/WnQycj30WtpOh7HTvp3PAR9Nd37vXvu87Mrmr2RkcDCgBI7jGzZrWmela/fed++76ehh6JBFJAiQSajYB6ZBbOOdv67Tv32/et6/jvUCK9TCmfSKCOBhTJbSTfJDlKsudGp5NcS3Inyb0kXyd5X7a9p6e6kCyRfJXkc9nrDSR3ZT/nJ7Nha32hYwFFsgTgu6gNYdoI4G6SGzt1/g4pA/iKmW0EcCOAe7Pv2OtTXe4DsM+9/iaAb5vZ1QBOArhnVq5qFnTyDnU9gFEz229m4wCeQG0KSM8wsyNm9krWPo3aX7LV6OGpLiTXAPgMgO9lrwngZgBPZ7v01PedSicDajWAg+71oWxbTyK5HsB1AHah4FSXLvUdAF8FUM1erwAwZmbl7HVP/5wnUqfEDCC5GMCPANxvZqf8e5eb6tJtSH4WwHEze3m2r2WuaHWCYTsOA1jrXq/JtvUUkkOoBdPjZnZpMPExkqvM7EiPTXW5CcBtJG8FMAxgCYCHACwlOZjdpXry55ynk3eo3QCuyXqA5qE2+/fZDp5/xmW/PzwKYJ+Zfcu91ZNTXczsa2a2xszWo/bz/JmZfR7ATgCfy3brme9bRMcCKvvX6ksAXkDtl/WnzOz1Tp2/Q24C8AUAN7tVom5F/011eQDAl0mOovY71aOzfD0do5ESIoHUKSESSAElEkgBJRJIASUSSAElEkgBJRJIASUSSAElEui30MHqAmv5ClcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD7CAYAAAASJLr7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVtklEQVR4nO3da2yc5ZUH8P+x5+LxPc7FuTiQACE0hRK6EQui2guQiqUV9EOFYKtutULiC12BWqnQ1X7YlbZS+6WUD1UltnQ3ldhSlhYtYlFbBHSXlVYhIaEFEkJCSIgTJ3YS38dje8ZnP8yb95w44+R1/NiOZ/4/CeWZd27v2By/Z57bEVUFEYVRt9gnQFRNGFBEATGgiAJiQBEFxIAiCogBRRTQnAJKRO4RkQMickhEngx1UkRLlVzuOJSI1AP4CMB2AN0AdgF4SFX3hTs9oqUlNYfn3grgkKoeBgAReR7A/QBmDKh0W06znW1zeEuixTd+ahCTg2NS6b65BNQ6AMfc7W4Af3qxJ2Q727D1x38zh7ckWnzvPvrzGe+b904JEXlERHaLyO7i4Nh8vx3RoppLQB0HsN7d7oqOnUdVn1HVbaq6LdWWm8PbEV355hJQuwBsEpGNIpIB8CCAl8OcFtHSdNnfoVS1KCLfBPBbAPUAfqaqHwQ7M6IlaC6dElDVVwG8GuhciJY8zpQgCogBRRQQA4ooIAYUUUAMKKKAGFBEATGgiAJiQBEFxIAiCogBRRQQA4ooIAYUUUAMKKKAGFBEATGgiAJiQBEFxIAiCogBRRQQA4ooIAYUUUAMKKKALhlQIvIzEekVkffdsQ4ReU1EDkb/Lpvf0yRaGpJcof4NwD3Tjj0J4HVV3QTg9eg2Uc27ZECp6v8AODvt8P0AdkTtHQC+Eva0iJamy/0O1amqPVH7JIDOQOdDtKTNuVNCyxXbZqzaxuobVEsuN6BOicgaAIj+7Z3pgay+QbXkcgPqZQDfiNrfAPCfYU6HaGlL0m3+CwD/B2CziHSLyMMAvg9gu4gcBHB3dJuo5l2y+oaqPjTDXXcFPheiJY8zJYgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFASfblWy8ib4rIPhH5QEQei46zpA3RNEmuUEUA31bVLQBuA/CoiGwBS9oQXSBJOZseVd0TtYcB7AewDixpQ3SBWX2HEpENAG4BsBMJS9qw+gbVksQBJSLNAH4F4HFVHfL3XaykDatvUC1JFFAikkY5mJ5T1V9HhxOXtCGqFUl6+QTAswD2q+oP3V0saUM0zSWrbwC4A8DXAbwnIu9Gx/4e5RI2L0TlbY4CeGBezpBoCUlSzuZ/AcgMd7OkzSKrE/vqOl6qj9vpuqnFOJ2ax5kSRAExoIgCSvIdiq5g/Xkbiqh3aV46OxG3mzPjcXu8ZL/yo70dcbs0mInb2eU2XriqbSTcydYAXqGIAmJAEQXElG8e9A01x+3xsXTcXt5h6VM2VYzbvqduJjd29MTt3b3r7fUn7FfYlLPUbkXO3itTX4rbe7u74vbU6ay9QbM9ZiJv6R/aLnlq5PAKRRQQA4ooIKZ8CfgUbmXrpXu9xKVwWrS/Wc1ZS8k+33HMjqfseEnt8ZNqA7WfjC6P22MTlkamUtazt7mjL25f03Q6bv9xcJ29Zp+boKw2Xt/YZj17Y6OWCp44Yznf2uWDqGTUnU9TZrLiY2oFr1BEATGgiAJiypdAzg2SzmTr8u64fSBlay0/Orsmbh936dO6JkufVmWOx+2zxaa4/fbpq+P2p6dsEFanLFW7avXZuH17++G43VhnaeTu0lX23HpLR33nYjZtvY6NHZa2nT5h53yyriVur18xELenplxvYY3jFYooIAYUUUBM+SqYPtC6umU4bk+5nrGBgvWYvde/Nm7ftOxE3D6+wlKm0TONcXtvj/W8DU02xO3GlKWXpSn7e1efsoHXepe2+QHc4ZK9Tn7KBmfbs9aD19Q5ao8ZsVSt4HrqWhsLcbsuZ6mglxLrXVzVbOcwVkxXenjN4BWKKCAGFFFATPkqKE6d/3dmRYOlNIWSpTQ9Q61xu++s9YBd03Imbm9ZdTJu/2HSDbBO2qDt6KSlZ12NA/a+HZae5VIr4/bQhKVqxSl7nYP5Vfb4euupa0tbynfDylNx+9OsbfY7NGrp4kjBXr+11Z7rewJ9ateYnqjYzrvPVSt4hSIKiAFFFBBTvohf7dpYf37P1pSbX3emYAOvk0VLt8RtY3NgwFKvrpaBuN3Rainc+KRbduHSpK5sf9y+JmtbHban83F7T78t3yi4Fbg9eUtBPd9z6HswVzTa+ajrvSy4c2vLWY9fQ8rSSJ/u9g7aXMfWJnt8i5u7OOk2kKlmSfblaxCRt0XkD1H1jX+Kjm8UkZ0ickhEfikitZcwE02TJOUbB3Cnqt4MYCuAe0TkNgA/APCUql4HoB/Aw/N2lkRLRJJ9+RTAuW6udPSfArgTwF9Hx3cA+EcAPwl/ivPHb14yU08eAHw6bL1hPW4+nl+m0dJsvWEDbuOUMZc+5VwvmR8s7mywdku9pUwd9XZON+ZsruDxQnvcfveUGyAechu2pG0gePUye/3VTbYtfXPaPn8+YwlGxq0m7moeiNvZOjveN2qp78iE9RAOqp1Dyc05rJVlHUn3Nq+Pdo3tBfAagI8BDKjquZ9wN8olbio9l9U3qGYkCihVLanqVgBdAG4FcEPSN2D1Daols+rlU9UBEXkTwO0A2kUkFV2lugAcv/izrzx+rpxP84ZcCgOc34tVHLLUKNVqvWe+N6zXrfAdGrb5e7kOS7fW5KzdmbV2Qe1Xsm/cLvqnJ23guK9gr19yvXPZnKVVfslJzvXOjUzaoO2kGxT2vZyrGi1FXJcbQCU+hZtsts8+OmI/u7Nu6UfTBltBXM2S9PKtFJH2qJ0DsB3lKoZvAvhq9DBW3yBCsivUGgA7RKQe5QB8QVVfEZF9AJ4XkX8GsBflkjdENS1JL98fUS4DOv34YZS/Ty1ZxwctJTkhNlDZkK68ZAEAkLbUKOV60nzKVF9v7QmXkk24wc0pV9BkzKWbA5Mr4vZQ0dKziSn7VWVcb9tV7QMVT9PPtTudt7RzbLzycKFfsrEsa4PIPYXKg8V+gLi1wXoLJ9w+gRNue+ckm71UA049IgqIAUUUUM3N5fMDm36pwbBbElE/bcVuttVSLN9XVRi25xwZt33z6urs+aWCpXl9Jy3teccN+F6/3PbTW+UGmP15+JXCnj8+NG49bH5Aecr1ZvpzK7o9AwdHbUjDzzP0r59xq4ZzaevlS7l0N5uxn9VEiz0m7dLjasYrFFFADCiigGou5Ts5WrnXqiVTeTtk4PwVvL4A2WSL9Yb5QeK0q3bhE7Xz5vjlLV3cX7J9/E422fn51xlyq2jzhcr74KVd72SL63lb49Lc5VlbsjE4aedzdMjmK+ZdT+CES/9821cP8Wmhb+ea7BwaOJePiGaLAUUUUM2lfDO52IYifkD2Mx22ycmGnG3G8t6Q7cv3yYBtm9zRaDPs77luX9zemLWevROT7XF718CGuH3gtK38zbsUsTRpfwe1ZO1SztpNbi5fps5Sx5UZS1n9Ri5+jp8ftB10qazvFRx1aaFPiUeHradx1QpLNdsb7OdQzZu38ApFFBADiiggpnwJ+Bq1HWnrJRspWZrUP27z5Ubylva0uNTr1saP4/YXGy3dennU0qFXx26M2354udMt/fArjQtuzt6wS8P8piunxmzph9/22adqPg3zPZYTE5buFgv2Xn6+YnuTnb8f5P1sh+1J2JK2uYJ7TtsmM9WGVyiigBhQRAEx5ZulXa4Imq8t63vzbl5ni5cbXE/a2/lr4/b7BUsF3zi9OW771b4+betzq4ZPlSoPTk+5TVH8nL3RnL3XeYPOrjfPz9Pzx/0cvJLbh7Axa5/r2jab4djq6gV/ofWjuH2mZOe/B0z5iCgBBhRRQEz5It0HbRBVG85farDhahuE9fPxBo/acoz+dktpPne1pXy+J+13PZ+J237Omx9IXeZ6zMaL9usZHLb3LY64fQOL9jriXrOYsd62cdfzVtdg75Vz8+taXc+hX33s+RTU77k3MOE2onEp7q6RjdZ2qXI14xWKKCAGFFFATPkidQWXOnWcv0nLmkYbVPXLKPzaDB2xH+WhM7bRSmer7XHnU6k6lz75XrWse4wfJC02uvly7vGTo24w183xk4ylrU2ul6/Rz/FzPX5+776Mqz7i01Gf8uVdD2df3rZlXpm1uYK7+msjzfMSX6Gi7Zj3isgr0W1W3yCaZjYp32Mob3B5DqtvEE2TKOUTkS4AXwLwPQDfEhFBFVTf8NbeZMsyti7vPu++u9s+iNtP5bfH7bMpS4dk0qVDQzZf7oRbXuEHXtVN1GtocL1tbqWtT/k6mmx18KpmS6v6Gi3dyhcsSWjKuRW7rtKH7130WzF7Ta5AW5ubg+erdZwYsR5OP7fQbyt9EFYXuFYkvUL9CMB3AJz7DS9HwuobRLUkyd7mXwbQq6rvXM4bsJwN1ZIkKd8dAO4TkXsBNABoBfA0ElbfUNVnADwDAM3Xr9ZKj7nS7B9cfd7tT0dtBe6RTy2NSQ1ZylRqcj14roetOOke0+9Wxebtb9lwh6V89SvsR5RySyTWtdj2xVc1nY3b6XrrUTyTtgHWla5+7pqcPddvzOJX6bZm7I+dX6Lii6x1ZOy4lxI7z25XDK4WXfIKparfVdUuVd0A4EEAb6jq18DqG0QXmMvA7hMod1AcQvk7FatvUM2bbcG13wP4fdRe8tU3vGPHbCtlTMz8dyY1bCmc376vbpn1jF3bacsZiu5Bhws2XxB5/+TKmbCvdbvSbdGcFkspx0v2K/Qbp7RlrXeuPW3pnN/e2ReWO+2KuPlUsMEN8qbcZi/+Mb5G8MHB2uvZ8zj1iCggBhRRQJzLF1m//syM9x3rtnSwWO9WubbbgOamTlvisbnFBomHitar1r/CbcXcYunZ1cusF64p7ffT83PqrCft1Lit2D0zaj17BbeJSmOHvc6KtKVk+4esB/PDY9auS9nrNza6pRwuRaxzA83trqZwrad5Hq9QRAExoIgCYsqXwLKVljL5zUxm2ndubMrSudGitVc22cDouJuz99n2nri9KmPv9dGo9Qr2jNncuVG3h54/n7Vu7762jJ3PW2c2xe33P7EZYupW+67t7MdsTJYqzwOsdbxCEQXEgCIKiClfAs1ulauvItGetiUVM21Csrm9N25PZCxNGsvb9sjbmj+J2xk3aPtW33Vxu79gPYR+bz2/6tZvCPNhv6WLI26VcdcamwdI4fEKRRQQA4ooIKZ8szTgUq9dBUvzWt3cuaFxmyM3XLR06/SYzZfzrs/YQPC/9P553O4ZtrTwug6bH5h3PYeHe23Q2W/GsqLZehR9zdzZGpu0weJcujbq5M4Fr1BEATGgiAJiyheIT/M8v5nJTP579Ia4/daRa+K2H6i9qe1E3P75rtvj9pZ/OGYvlLJf54HHrorbU502iNzm5uAlkR9nyjcbvEIRBcSAIgqIKd8V4L9OWF3d1ctsLl971gaRd57ZELf9UpNSly2d0N3vx+21nwuzke/y5vylH0QxXqGIAmJAEQXElO8KdrZgq3GPfWKp3ebrbQvE/Pf8MzaCFlfSvc2PABgGUAJQVNVtItIB4JcANgA4AuABVZ3dohqiKjOblO8vVXWrqm6Lbj8J4HVV3QTg9eg2UU2bS8p3P4C/iNo7UN6v74k5ng/NJG0bpBw4ssYO52ywdbUbCKbFkfQKpQB+JyLviMgj0bFOVT23dvskgM7gZ0e0xCS9Qn1BVY+LyCoAr4nIh/5OVVXxdS2dKAAfAYDsqtZKDyGqGokCSlWPR//2ishLKG/BfEpE1qhqj4isAdA7w3OXXPWNK9H6rpn3DaQrR5L6UE0i0nKuDeCLAN4H8DLKVTcAVt8gApDsCtUJ4KVyFVCkAPy7qv5GRHYBeEFEHgZwFMAD83eaREvDJQMqqrJxc4XjZwDcNR8nRbRUceoRUUAMKKKAGFBEATGgiAJiQBEFxIAiCogBRRQQA4ooIAYUUUAMKKKAGFBEATGgiAJiQBEFxIAiCogBRRQQA4ooIAYUUUAMKKKAGFBEATGgiAJiQBEFlCigRKRdRF4UkQ9FZL+I3C4iHSLymogcjP5dNt8nS3SlS3qFehrAb1T1BpS3FNsPVt8gukCSnWPbAPwZgGcBQFUnVHUA5eobO6KH7QDwlfk5RaKlI8kVaiOAPgD/KiJ7ReSn0ZbMrL5BNE2SgEoB+DyAn6jqLQBGMS29U1VFueTNBUTkERHZLSK7i4NjlR5CVDWSBFQ3gG5V3RndfhHlADsVVd3ApapvqOo2Vd2WasuFOGeiK9YlA0pVTwI4JiKbo0N3AdgHVt8gukDSgmt/B+A5EckAOAzgb1EORlbfIHKSFlx7F8C2Cnex+gaRw5kSRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKKAkxQI2i8i77r8hEXmc5WyILpRk59gDqrpVVbcC+BMAeQAvgeVsiC4w25TvLgAfq+pRsJwN0QVmG1APAvhF1E5UzobVN6iWJA6oaF/z+wD8x/T7LlbOhtU3qJbM5gr1VwD2qOqp6HaicjZEtWQ2AfUQLN0DWM6G6AJJq8A3AdgO4Nfu8PcBbBeRgwDujm4T1TQpf/1ZoDcT6UO5pOjpBXvTK8MK1NZnrvbPe7Wqrqx0x4IGFACIyG5VrVRrqmrV2meutc/rceoRUUAMKKKAFiOgnlmE91xstfaZa+3zxhb8OxRRNWPKRxTQggaUiNwjIgdE5JCIVN3sdBFZLyJvisg+EflARB6Ljlf1UhcRqReRvSLySnR7o4jsjH7Pv4ymrdWEBQsoEakH8GOUpzBtAfCQiGxZqPdfIEUA31bVLQBuA/Bo9BmrfanLYwD2u9s/APCUql4HoB/Aw4tyVotgIa9QtwI4pKqHVXUCwPMoLwGpGqrao6p7ovYwyv+TrUMVL3URkS4AXwLw0+i2ALgTwIvRQ6rq817KQgbUOgDH3O3u6FhVEpENAG4BsBMJl7osUT8C8B0AU9Ht5QAGVLUY3a7q3/N07JSYByLSDOBXAB5X1SF/38WWuiw1IvJlAL2q+s5in8uVIrWA73UcwHp3uys6VlVEJI1yMD2nqucmE58SkTWq2lNlS13uAHCfiNwLoAFAK4CnAbSLSCq6SlXl73kmC3mF2gVgU9QDlEF59e/LC/j+8y76/vAsgP2q+kN3V1UudVHV76pql6puQPn3+Yaqfg3AmwC+Gj2saj5vEgsWUNFfq28C+C3KX9ZfUNUPFur9F8gdAL4O4E63S9S9qL2lLk8A+JaIHEL5O9Wzi3w+C4YzJYgCYqcEUUAMKKKAGFBEATGgiAJiQBEFxIAiCogBRRQQA4oooP8HeIjOLoco8pAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD7CAYAAAASJLr7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVdUlEQVR4nO3dfWxd9XkH8O/je/3+Esd5cZw4JCGkQLSW0EYUxjQNUjYKFSC1QtCq6iYk/mknWDsVOu2PTdq08k+BP6ZKqHTLH12B0aJRhEoRBU1dtywhMF4SSEJCsJPYebEdv/v63vvsj3tynseOLz6Of7bje74fCfG75557z+/aee55/HsVVQURhVG11BUgqiQMKKKAGFBEATGgiAJiQBEFxIAiCmheASUit4vIhyJyREQeDVUpouVKLrUfSkQyAA4BuA1AN4C9AO5X1QPhqke0vGTn8dobABxR1aMAICLPALgbQNmAyjQ2aratbR6XJFp6+b4+FEZGZKbn5hNQGwB0ucfdAL74aS/ItrVhw189PI9LEi29E48/Ufa5BW+UEJEHRWSfiOwrjIws9OWIltR8AuoEgI3ucWd0bApVfUpVd6rqzkxj4zwuR3T5m09A7QWwTUS2iEgNgPsAvBimWkTL0yX/DaWqeRH5DoBXAGQA/FRV3w9WM6JlaD6NElDVlwG8HKguRMseR0oQBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFAswaUiPxURE6LyHvuWJuIvCoih6P/r1zYahItD0nuUP8K4PZpxx4F8JqqbgPwWvSYKPVmDShV/U8AfdMO3w1gd1TeDeCesNUiWp4u9W+odlU9FZV7ALQHqg/RsjbvRgkt7dhWdtc27r5BaXKpAdUrIh0AEP3/dLkTufsGpcmlBtSLAL4Vlb8F4D/CVIdoeUvSbP5zAP8N4GoR6RaRBwD8EMBtInIYwJeix0SpN+vuG6p6f5mndgWuC9Gyx5ESRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKKAk6/JtFJHXReSAiLwvIg9Fx7mlDdE0Se5QeQDfU9XtAG4E8G0R2Q5uaUN0kSTb2ZxS1f1ReQjAQQAbwC1tiC4yp7+hRGQzgOsB7EHCLW24+walSeKAEpEmAL8A8LCqDvrnPm1LG+6+QWmSKKBEpBqlYPqZqv4yOpx4SxuitEjSyicAngZwUFV/5J7iljZE08y6+waAmwF8E8C7IvJ2dOxvUNrC5rloe5vjAO5dkBoSLSNJtrP5HQAp8zS3tFliVZP2q5GCHS/Uld2llRYQR0oQBcSAIgooyd9QdBnzaZ7vuFD3VVmsK8bl+lP2K1+7bzIu1wxaue/a+rg8cA1Tx7ngHYooIAYUUUBM+RaAb3mrylm5WGPpk2bsfK2aPa3SdRP24GytlV37a7HGlVdaCifu/Zu67MKNH56Jy5MdrXG5ucteO3AN/4nMBe9QRAExoIgC4v08gcyE5VWF2gTpmUvDMuNWzjfZa2s2DcfllU2jcXl0wvK2oWFrbSuer47L1WMujXS/wWKHXWzzur64/HHXmri86u3zVs+zds7gH66z9x+xeq7Zb+9/5vOYUVXe1yfdrYK8QxEFxIAiCogpXwJTxsWVyWiKq61lDIP2Y607Zt9ZVZNWHltnKVxzm7Xg+ZRPTtTF5baP3LWylmKdv9p6dreuPxuXr2y28vEPLJ2Trp64XBi0aW1DG61uRdeIuOVZawnM5Nri8slb7BwZKjfUM314hyIKiAFFFBBTvhlIcWoK41uu1P3EsiNu6kSP61W9YiwuDndaS11Tt71P4aAdPzRpKdmKlbbuRnG9tdqN99v5NdZQN+UrcSJvlTsx2mp1dmP5Bm/ZFpebD9kb1Z+1ug132ueaWN8Sl6eMG3Qte/lVeTtesOOZ4fR9X6fvExMtIAYUUUBM+Wag0xqtdErKZ+XMuGvNO2fnj2yyc4pbLf0bzTfE5Wrr14WO2fi6L193IC5/tXVfXP6nTXfE5Xf+y9I2calXT39zXB6osxbCxlXWcXziTnd8q7XatX5k+VxVzr5n+661Jr/xVVbn6kH7jJOw+letcT3Zw3attOAdiiggBhRRQEz5LnBpnmbKj0ermrDvIHGnSdG14PVaixxWW6ftZJPvIPYXtOJwwVKsL9Ray+Ffb3glLn+944q4nOmx8yf7LMXKF6wOWm0XqF5h9cntsNa5c3W2CGl9r50/2mHl3PpcXG5+167besjqf26H1SGz0VLNQpelu5Usybp8dSLyvyLyf9HuG38fHd8iIntE5IiIPCsiNbO9F1GlS5LyTQC4VVWvA7ADwO0iciOAxwA8rqpXAegH8MCC1ZJomUiyLp8CuNAmVR39pwBuBfD16PhuAH8H4Mfhq7hw/EImU75ailPP82lelRuyV3Sp1HibpXC1Z910hvOWevkUMbfSLlK72loCBybt/N+M2ni/GrE6tLrOX93rxvsdtJa6ySZreTv7Wfs1TzTZB2hotPRvpM19aHetwhZL265ca9M9Th7vjMsrjtlr1+61z36qwaV/SIeka5tnolVjTwN4FcBHAAZU9UIS3o3SFjczvZa7b1BqJAooVS2o6g4AnQBuAHBN0gtw9w1Kkzm18qnqgIi8DuAmAK0iko3uUp0ATixEBReSn2mKKS12U8/LjLtFV1zKl29wnZstriXNTWeodjflnDsn02Gp1M7OrrjcWTcQl18+f11c7nZj8wbdTN5a68vF8AZrF8q7PtV8o+toHrFf+fCwpZTi8tHxK6w176p267HubLS6HWvriMvnr7SEbv0bNj6w5Yj9HI7c14Q0SNLKt0ZEWqNyPYDbUNrF8HUAX4tO4+4bREh2h+oAsFtEMigF4HOq+pKIHADwjIj8A4C3UNryhijVkrTyvYPSNqDTjx9F6e+pZSs7OvPOFcWkiXCZzmDNuEVdXO+cX6SlrtouOJBzSx/nrG3nk4HWuDw8YB2j6lLVsWts7NzoZku96rssnVtx2KWaE3bOZJO9z7A12iHXYHX7uNcG8B0XG/vn1xscW2vvP7LJUruGbktrWz6y8we3Vu5CLhx6RBQQA4oooNSN5Su6BVcmatyUhcnyC434DmA/XaLKTVT1LYHijtcOWLn+tEuTzqyIy+9vsnQu02gvLgxZ2uY7m6tXumWZXeuc9tr4uow7xXc6+9nIvv511meLjFsoJjvqFo1xaXGu1coTq+yJ/s9YSjm6xtK/kfVIBd6hiAJiQBEFlLqUr2p85tTO74zh0zpg2uIkjp+B4V/hF3LJWWY3JS3M2vA9NByz1E4zrrO1zHWrjtkFfDo62ewWWtlq+VxTu00Prq12UzbOWUpWe9R6grPWOIfqYddh7ZZoLtTZhTPjVvb1mWh1C7k0Ws46veO8kvAORRQQA4oooNSlfOX4jsrpfMtYvtnlYbUujRmyH2V9j53vU6DhHdYJu3WDLXE8nLOWtJ7j1pHafMjes7nbrlUzaHXI19sFBq6yFrbcartu0dXfj9nL1lr6N7HWvadbT88v++zLfpGZtg/ttdVDVu65wVod/T6/mdHK/R6v3E9GtAQYUEQBMeVLwO+BK/WW0kjG0hjNWrrlp3X4fW872/vj8p93/j4u7xm6Mi7/qsvGy/kWwtPr3PjARtfCNmTl6iE7PzvoOlizNlZwFG4G8Zjf6NeKU3Ybge8ItuNja9w4wCvsferO2j+p0c0216Wm1XqaC6OVu2AL71BEATGgiAJiyjdHVWfd+DrXs6v1lv7l1vi5IFbsOmZ73f7tsa/ae7pWr+oJ31tsKVbDKTteM+DWBpzSSerGKQ67cYNFq3PRZXn+tYUGl77WWLlQ7z6je22u1a617rO9cbml1loyG7I28/fQOfvsrt+44vAORRQQA4ooIKZ8kdo+15k5bQ3cXKulQFmXSvk0LNdi+dBYp6V8mnWdv+N2jt+sLTPhx7xZKuX2T0N9ryv32/sX3ezgiRUzf4Zy82OntOa1WItclZt9XHCthVrl0k7bnhcne1vjcn+TteZlXSvo6BHXZFnBeIciCogBRRQQU76Ib8GabJo6v6Dox+ydn/lH5tfr852tBdeH6Zdidg1vKLhxbsWVfq1nS7HGh3weOnMdfJqXd2uKFmvLJH2+QjrzeL+Cm3bh01r/eau7bMze6HrX6dyXvn9eie9Q0XLMb4nIS9Fj7r5BNM1cUr6HUFrg8gLuvkE0TaJ7soh0ArgTwD8C+K6ICCpg9w0vt8KldevHpzzXVG8dlLlz1lrl054s/NQGPxVk5u8sf0a+zk+pcNMoRlyHrNvpY3Sde3c3u9jP8PUteH4KSWbMdxy71kW3Rl9Do33+ovvsI9WWv2ZdOuf3Ha5vsdfm+tKx/LKX9A71BIDvw/r9VyHh7htEaZJkbfOvADitqm9eygW4nQ2lSZKU72YAd4nIHQDqALQAeBIJd99Q1acAPAUAtRs3Los1ePMTU7cHGx62JrM22ygDDWdcx+Uav1DJzLt1+FTQr5s32exm2uZssZT6fnvP3Aq3nPIV9sU03m/nV/fZ+/gUUf1af26aie903tR5Ni5f3Wq9yKfGLMU9alXG2Kht+1FssvfPZi3vzCF9Zr1DqeoPVLVTVTcDuA/Ab1X1G+DuG0QXmU/H7iMoNVAcQelvKu6+Qak31w3X3gDwRlRe9rtveL71K9M9tUtt6jLLlkrlmu37aHy164Rd79Y4dkluZtx+3HV9foM2f469p19nr6rTJj10rLSBdMcH3PLLrp75Fkvnrt16Mi6P5a3l8ONja+19TtjiMKf6W+Jyzu3z6xei8dfa9rlTcfnI/o1IMw49IgqIAUUUUPoGW5VRqC/fAOl35hhrn3kG63i7tW7Vttk6y5M5+xEXGlxrXotbdMWyNox2+q07XGfzpL32k5OWntW4RVGmjCdss2bEjnpLEd/4nz+Iy1c9b52wY+1WifNXWrnOVcdvRDe6weqW9jTP4x2KKCAGFFFATPkS8Ovs+a8gP+3CL2wyMeJaCd0sXb9bR77enbLNUq/rNlv/+HsnOuJy8aylYX53ED9Ob2y9pZ11NZarvfF7S/M2vuY6XlvdEtA3+dGFs2+PkXH7E/udS9KOdyiigBhQRAEx5UvAT0/wLXv+eGbQj/+zcqHJL9dsZ/iFX27ffiAuf6ahJy6/887muFztZwG7qRk+HfU7iOSO2Vi7Bre3b/ctCIJp3sx4hyIKiAFFFBBTvjnys2ITbRzmGsx8x6vvzN21wlK+xw7/WVyu67HU0Xcc++m+1YNWB79m4JS1BeeRnfk0kmne7HiHIgqIAUUUEFO+BebTwkKZ9fGePLYrLp/fb5vjFlvc+SssX6z/wGbpXvGrvrgsn9g0jcnP2SZuI512/phb4CWJrJvWkmPKNyveoYgCYkARBcSU7zJw8t12e+CmkRSarWUvc9qaBSdWWdNhvtUt0jJpM3CP3WPH58OvV0iz4x2KKCAGFFFATPkuY5kh69hd/ztL/3q+aMenpnZh0jy6dEnXNv8YwBCAAoC8qu4UkTYAzwLYDOBjAPeqav/CVJNoeZhLyneLqu5Q1Z3R40cBvKaq2wC8Fj0mSrX5pHx3A/iTqLwbpfX6HplnfaiMsVWW5tX2uQVe6lzHaytb5JZa0juUAviNiLwpIg9Gx9pV9cIKhz0A2md+KVF6JL1D/ZGqnhCRtQBeFZEP/JOqquL3kXSiAHwQADIrV86rskSXu0QBpaonov+fFpEXUFqCuVdEOlT1lIh0ADhd5rXLbveNy1H/dv+j44/xcpVkf6hGEWm+UAbwpwDeA/AiSrtuANx9gwhAsjtUO4AXSruAIgvg31T11yKyF8BzIvIAgOMA7l24ahItD7MGVLTLxnUzHD8HYNfFryBKLw49IgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBhQRAExoIgCYkARBcSAIgqIAUUUEAOKKCAGFFFADCiigBIFlIi0isjzIvKBiBwUkZtEpE1EXhWRw9H/uSwspV7SO9STAH6tqtegtKTYQXD3DaKLJFk5dgWAPwbwNACoak5VB1DafWN3dNpuAPcsTBWJlo8kd6gtAM4A+BcReUtEfhItyczdN4imSRJQWQCfB/BjVb0ewAimpXeqqiizgr2IPCgi+0RkX2FkZL71JbqsJQmobgDdqronevw8SgHWG+26gdl231DVnaq6M9PYGKLORJetWQNKVXsAdInI1dGhXQAOgLtvEF0k6YZrfwngZyJSA+AogL9AKRi5+waRk3TDtbcB7JzhKe6+QeRwpARRQAwoooAYUEQBMaCIAmJAEQXEgCIKiAFFFBADiiggBhRRQAwoooAYUEQBMaCIAmJAEQXEgCIKiAFFFBADiiggBhRRQAwoooAYUEQBMaCIAmJAEQXEgCIKKMlmAVeLyNvuv0EReZjb2RBdLMnKsR+q6g5V3QHgCwBGAbwAbmdDdJG5pny7AHykqsfB7WyILjLXgLoPwM+jcqLtbLj7BqVJ4oCK1jW/C8C/T3/u07az4e4blCZzuUN9GcB+Ve2NHifazoYoTeYSUPfD0j2A29kQXSTpLvCNAG4D8Et3+IcAbhORwwC+FD0mSjUp/fmzSBcTOYPSlqJnF+2il4fVSNdnrvTPu0lV18z0xKIGFACIyD5VnWmvqYqVts+cts/rcegRUUAMKKKAliKgnlqCay61tH3mtH3e2KL/DUVUyZjyEQW0qAElIreLyIcickREKm50uohsFJHXReSAiLwvIg9Fxyt6qouIZETkLRF5KXq8RUT2RL/nZ6Nha6mwaAElIhkA/4zSEKbtAO4Xke2Ldf1FkgfwPVXdDuBGAN+OPmOlT3V5CMBB9/gxAI+r6lUA+gE8sCS1WgKLeYe6AcARVT2qqjkAz6A0BaRiqOopVd0flYdQ+ke2ARU81UVEOgHcCeAn0WMBcCuA56NTKurzzmYxA2oDgC73uDs6VpFEZDOA6wHsQcKpLsvUEwC+D6AYPV4FYEBV89Hjiv49T8dGiQUgIk0AfgHgYVUd9M992lSX5UZEvgLgtKq+udR1uVxkF/FaJwBsdI87o2MVRUSqUQqmn6nqhcHEvSLSoaqnKmyqy80A7hKROwDUAWgB8CSAVhHJRnepivw9l7OYd6i9ALZFLUA1KM3+fXERr7/gor8fngZwUFV/5J6qyKkuqvoDVe1U1c0o/T5/q6rfAPA6gK9Fp1XM501i0QIq+rb6DoBXUPpj/TlVfX+xrr9IbgbwTQC3ulWi7kD6pro8AuC7InIEpb+pnl7i+iwajpQgCoiNEkQBMaCIAmJAEQXEgCIKiAFFFBADiiggBhRRQAwoooD+H6zbj7xIKDZyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory_batch: 6\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02280a4d50>, 36, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 795.2617\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 423.1880\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 145.5013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 40.7892\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 12.4008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.6222\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.8281\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.1955\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.6164\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0262\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0182\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1998\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0167\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2666\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0381\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0197\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0033\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4807\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4807\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4806\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4806\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0064\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4805\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0143\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4804\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0033\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4804\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4803\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4803\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4802\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4800\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4800\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4799\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4798\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4798\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4797\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4797\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4796\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4795\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4795\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4794\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4794\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4793\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4792\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4792\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4791\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4791\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4790\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4789\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4789\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4788\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4788\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4787\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4787\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4786\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4785\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4785\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4784\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4784\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4783\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4783\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4782\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4781\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4781\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4780\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4780\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4778\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4778\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4776\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4775\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4775\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4773\n",
      "Memory_batch: 7\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f028442b510>, 56, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 906.5330\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4773\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 198.5401\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 75.0033\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4773\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 44.9395\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4773\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 23.5827\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4773\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 12.0605\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.8819\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4833\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3824\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4774\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0516\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4775\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.6020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4775\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0177\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4776\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0423\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4776\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0027\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4776\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5760\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5591\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.9205\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0096\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4777\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1617\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4778\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4778\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4778\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4779\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4780\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0477\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4780\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4780\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4781\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4781\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4782\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4782\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4783\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4783\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4784\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4784\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4785\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4785\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4786\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4786\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4786\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4787\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4787\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4788\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4788\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4789\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4790\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4790\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4791\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4791\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4792\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4792\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4793\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4793\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4794\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4794\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4795\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4796\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4796\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4797\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4797\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4798\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4798\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4799\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4799\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4800\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4800\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4801\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4802\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4802\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4803\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4803\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4804\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4804\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4805\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4805\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4806\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4806\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4807\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4807\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4808\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4818\n",
      "Memory_batch: 8\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f0249734d50>, 43, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 380.1822\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 108.4796\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 19.0577\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 14.1841\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.8329\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.2303\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2546\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.3264\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.0561\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2420\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0245\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0141\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4149\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0130\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0156\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0197\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3497\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0286\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0276\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0191\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0156\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0121\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0115\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0948\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0117\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0088\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0087\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0087\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0086\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0084\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0084\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0083\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0083\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0081\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0079\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0075\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0074\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0072\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0071\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0070\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0068\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0066\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0064\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0061\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0059\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0057\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0054\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0052\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0050\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0048\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0040\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0038\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0033\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0031\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0029\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0027\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0022\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0018\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4810\n",
      "Memory_batch: 9\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f028433aa50>, 35, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 325.5547\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 104.2555\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 40.9414\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 21.6821\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 7.2633\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.9322\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.1653\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.5433\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.2330\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.0836\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.0070\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.1293\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8867\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8049\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.7222\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.6341\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5884\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4298\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2852\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1626\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0382\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0157\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0151\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0148\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0144\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0139\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0133\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0128\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0123\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0120\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0116\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0112\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0108\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0104\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0101\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0097\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0088\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0085\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0082\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0077\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0074\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0072\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0070\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0067\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0065\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0064\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0063\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0062\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0061\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0060\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0058\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0057\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0056\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0055\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0053\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0053\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0052\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0051\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0050\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0050\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0049\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0049\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0048\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0048\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0047\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0047\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0047\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0047\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0047\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0047\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0046\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0046\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0046\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0045\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9794\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0044\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9795\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9796\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0042\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9797\n",
      "Validation acc: 0.4832\n",
      "Memory_batch: 10\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02280b5890>, 57, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 197.2307\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9793\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 73.1151\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 40.8486\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 18.7220\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 7.7572\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.8295\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.0800\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.9011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.7669\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.2423\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.3413\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8040\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5433\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3178\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2178\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1305\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0368\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0175\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0046\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0152\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0201\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0194\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0115\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0051\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0681\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2695\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0688\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0021\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9781\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0008\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9784\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9787\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9789\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9790\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9791\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9792\n",
      "Validation acc: 0.4834\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD7CAYAAAASJLr7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN2klEQVR4nO3dX4xc5X3G8e+za5vFBmr+1XKwFVsFEblSY1oLiGgrFeKWkghyESFIFEUR0qpSUoESKSG9aqVeJDdJuKgiWZDWFzRASVARikKRcRRVqVwMJgnYUDs0CDv+EyiuXQP+s/vrxRzveXd3xj7r+e3szszzkUZ7zpmZPe9o/fi8855z3p8iAjPLMbLQDTAbJA6UWSIHyiyRA2WWyIEyS+RAmSXqKlCSbpf0uqR9kh7MapRZv9KFnoeSNAr8F7AZ2A+8ANwbEbvzmmfWX5Z08d4bgX0R8QaApMeAu4COgVqmi2KMFV3s0mzhfcAJTsVJtXuum0BdA7xVrO8HbjrXG8ZYwU26rYtdmi28HbGt43PdBKoRSePAOMAYy+d7d2YLqptBiQPA2mJ9TbVtmojYEhGbImLTUi7qYndmi183gXoBuE7SeknLgHuAp3OaZdafLrjLFxFnJH0JeBYYBb4XEa+mtcysD3X1HSoifgT8KKktZn3PV0qYJXKgzBI5UGaJHCizRA6UWSIHyiyRA2WWyIEyS+RAmSVyoMwSOVBmiRwos0QOlFkiB8oskQNllsiBMkvkQJklcqDMEjlQZokcKLNEDpRZovMGStL3JB2R9Eqx7QpJz0naW/28fH6badYfmhyh/gm4fca2B4FtEXEdsK1aNxt65w1URPwU+J8Zm+8CtlbLW4FP5TbLrD9d6HeoVRFxsFo+BKxKao9ZX+t6UCJaFds6Vm2TNC5pp6SdpznZ7e7MFrULDdRhSasBqp9HOr3Q1TdsmFxooJ4GPl8tfx7415zmmPW3JsPm3wf+A7he0n5J9wHfADZL2gt8vFo3G3rnrb4REfd2eMq1Pc1m8JUSZokcKLNEDpRZIgfKLJEDZZbIgTJL5ECZJXKgzBI5UGaJHCizRA6UWSIHyiyRA2WWyIEyS+RAmSVyoMwSOVBmiRwos0QOlFkiB8oskQNllsiBMkvUZF6+tZK2S9ot6VVJ91fbXdLGbIYmR6gzwFciYgNwM/BFSRtwSRuzWZqUszkYES9Vy8eBPcA1uKSN2SznnTm2JGkdcAOwg4YlbSSNA+MAYyy/4Iaa9YPGgxKSLgF+ADwQEcfK585V0sbVN2yYNAqUpKW0wvRoRPyw2ty4pI3ZsGgyyifgEWBPRHyreMolbcxmaPId6hbgc8AvJb1cbfsbWiVsnqjK27wJ3D0vLTTrI03K2fw7oA5Pu6SNWcFXSpglcqDMEjlQZokcKLNEDpRZIgfKLJEDZZbIgTJL5ECZJXKgzBI5UGaJ5nSDoS0OWlL/2eLMmQVsic3kI5RZIgfKLJG7fIuZirtmop5hwN28xctHKLNEDpRZInf55oGWLmu7PU6fmtvvGR2t3ztZTCo1OXFB7boQf/KLD6aWf/pXN00t62c/71kb+omPUGaJHCizRO7yzYM4c3pquey2daT2c+CU3TyN1K+JaD/6l+XZ37w8tfx7z39havnan+1K39egaTIv35ik/5T086r6xt9V29dL2iFpn6THJbX/4mA2RJp0+U4Ct0bER4GNwO2Sbga+CXw7Iq4F3gXum7dWmvWJJvPyBfB/1erS6hHArcBnqu1bgb8FvpvfxP6gi4p52yfqUbhGJ2E1UiwWXbvJhTmZ+xcf2ji1fC3u5s1F07nNR6tZY48AzwG/Ao5GxNm/8n5aJW7avXdc0k5JO09zMqHJZotXo0BFxEREbATWADcCH2m6A1ffsGEyp1G+iDgqaTvwMWClpCXVUWoNcGA+GrjodLq+7mSDo+9IPeI3esmK+r2n6hO+MTFZ72qkXo56sadGVhTtLLqdjT7vEGoyyne1pJXV8sXAZlpVDLcDn65e5uobZjQ7Qq0GtkoapRXAJyLiGUm7gcck/T2wi1bJG7Oh1mSU7xe0yoDO3P4Gre9Tw2WOJ1JH/qD4ull02/TO0Xrze+/Vv74czRuZ40nhObZt9Kori99Td1Ym3n67btuJE+33ZW350iOzRA6UWSJfy5eknDhFF188tRzL6u0j79fX+MWJoptX3prRpJvXwOjll9crq6+ul/cfmlqcePud9m+e1oainzoP1w0OGh+hzBI5UGaJ3OVLMu2k5/Hj9RM7X5lanOgwIldeB1h2HSffr++W7TjC1qEbdvr3Pzy1fGx93QW96lgxanfsWNvfP7Jsad2GD4o22Hn5CGWWyIEyS+QuXzeK0bBpt10Ut29M65J16J6NXDzW/vefKH5PkxO4xWuWHK27aiv31iN1Z35ziHZGym7npZfW24s7jqed5C0++8iK5fVryu7uEPIRyiyRA2WWaCi6fF3dTXsuUd5e0f7/pmknfJcV025Mtr8fI053aFODbl75mslXXmv/+g7KtunS+pYNjdafq7zmsJwbMD7wrRxn+QhllsiBMks0FF2+kbUfqleO1yNVE4ePdPeLp43gdRiRK0bJtLw+wUpxZ245MjZthHCubejCRHmSt1xu0oQ5TjE9yHyEMkvkQJklGoou38S+/57/nXQ4yUtxa8bk/xYnPcsRwg6jjSNj9QnfcvKWJl2ssgLItG5kDyt3DCMfocwSOVBmiYaiy9dr0+7AjdPFcrG9HAnsNNdfeYvH0vpP1aTL55G3hdH4CFVNx7xL0jPVuqtvmM0wly7f/bQmuDzL1TfMZmhaLGAN8Ang4WpdtKpvPFm9ZCvwqXloX/+YnGj/iKgfpXK7RoqHph5x8uTUY/L996cetng1PUJ9B/gq9RQ4V9Kw+obZMGkyt/kngSMR8eKF7MDlbGyYNBnluwW4U9IdwBhwGfAQDatvRMQWYAvAZbpi8U7sVs5FN7PUxXzPRzfZ4TrAXrbBUpz3CBURX4+INRGxDrgHeD4iPourb5jN0s2J3a8BX5a0j9Z3KlffsKE314JrPwF+Ui0PVvWNxXKNm7t2fc2XHpklcqDMEjlQZokcKLNEDpRZIgfKLJEDZZbIgTJL5ECZJXKgzBI5UGaJHCizRA6UWSIHyiyRA2WWyIEyS+RAmSVyoMwSOVBmiRwos0QOlFmiRrMeSfo1cByYAM5ExCZJVwCPA+uAXwN3R8S789NMs/4wlyPUn0XExojYVK0/CGyLiOuAbdW62VDrpst3F62qG+DqG2ZA80AF8G+SXpQ0Xm1bFREHq+VDwKr01pn1maYzx/5xRByQ9LvAc5JeK5+MiJDUdsrTKoDjAGMs76qxZotdoyNURByofh4BnqI1BfNhSasBqp9HOrx3S0RsiohNS7kop9Vmi1ST+lArJF16dhn4c+AV4GlaVTfA1TfMgGZdvlXAU60qoCwB/jkifizpBeAJSfcBbwJ3z18zzfrDeQNVVdn4aJvt7wC3zUejzPqVr5QwS+RAmSVyoMwSOVBmiRwos0QOlFkiB8oskQNllsiBMkvkQJklcqDMEjlQZokcKLNEDpRZIgfKLJEDZZbIgTJL5ECZJXKgzBI5UGaJHCizRI0CJWmlpCclvSZpj6SPSbpC0nOS9lY/L5/vxpotdk2PUA8BP46Ij9CaUmwPrr5hNkuTmWN/B/hT4BGAiDgVEUdx9Q2zWZocodYDvwX+UdIuSQ9XUzK7+obZDE0CtQT4Q+C7EXEDcIIZ3buICFolb2aRNC5pp6SdpznZbXvNFrUmgdoP7I+IHdX6k7QC5uobZjOcN1ARcQh4S9L11abbgN24+obZLE0Lrv018KikZcAbwBdohdHVN8wKjQIVES8Dm9o85eobZgVfKWGWyIEyS+RAmSVyoMwSOVBmiRwos0QOlFkiB8oskQNllsiBMkvkQJklcqDMEjlQZokcKLNEDpRZIgfKLJEDZZbIgTJL5ECZJXKgzBI5UGaJHCizRE2KBVwv6eXicUzSAy5nYzZbk5ljX4+IjRGxEfgj4D3gKVzOxmyWuXb5bgN+FRFv4nI2ZrM0nYr5rHuA71fLjcrZSBoHxgHGWH4hbTTrG42PUNW85ncC/zLzuXOVs3H1DRsmc+ny/SXwUkQcrtYblbMxGyZzCdS91N09cDkbs1maVoFfAWwGflhs/gawWdJe4OPVutlQU+vrT492Jv2WVknRt3u208XhKobrMw/65/1wRFzd7omeBgpA0s6IaFdramAN22cets9b8qVHZokcKLNECxGoLQuwz4U2bJ952D7vlJ5/hzIbZO7ymSXqaaAk3S7pdUn7JA3c1emS1kraLmm3pFcl3V9tH+hbXSSNStol6Zlqfb2kHdXf+fHqsrWh0LNASRoF/oHWJUwbgHslbejV/nvkDPCViNgA3Ax8sfqMg36ry/3AnmL9m8C3I+Ja4F3gvgVp1QLo5RHqRmBfRLwREaeAx2jdAjIwIuJgRLxULR+n9Y/sGgb4VhdJa4BPAA9X6wJuBZ6sXjJQn/d8ehmoa4C3ivX91baBJGkdcAOwg4a3uvSp7wBfBSar9SuBoxFxplof6L/zTB6UmAeSLgF+ADwQEcfK5851q0u/kfRJ4EhEvLjQbVks5nqDYTcOAGuL9TXVtoEiaSmtMD0aEWcvJj4saXVEHBywW11uAe6UdAcwBlwGPASslLSkOkoN5N+5k14eoV4ArqtGgJbRuvv36R7uf95V3x8eAfZExLeKpwbyVpeI+HpErImIdbT+ns9HxGeB7cCnq5cNzOdtomeBqv63+hLwLK0v609ExKu92n+P3AJ8Dri1mCXqDobvVpevAV+WtI/Wd6pHFrg9PeMrJcwSeVDCLJEDZZbIgTJL5ECZJXKgzBI5UGaJHCizRA6UWaL/B50zPv0fKPMZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD7CAYAAAASJLr7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQhElEQVR4nO3dbYxc5XkG4Pvenf3yrr32+mNl77o1koHEqYRpLEpE+mXiyCUU8iOi0CiKKiT+JBGUSAnpr1ZqpUSKQvhRpbVCWirRACFBRShKioijKFHrYANpgx2CQTGsMV6n9trsp3d2n/6Y43kfz+56z3qend2ZuS8J7Ttnzsw54+We8+x7znlfmhlEJEbLSu+ASCNRoEQCKVAigRQokUAKlEggBUokUFWBIrmf5Gskj5N8KGqnROoVr/Y8FMlWAL8GsA/AEIAXAdxjZkfjdk+kvhSqeO1NAI6b2ZsAQPIJAHcCWDBQhc5u6+jpq2KTIitvavQsipNjnO+5agI1AOBt93gIwB9c6QUdPX3YdftfV7FJkZV39LmHF3xu2TslSN5H8jDJw8XJseXenMiKqiZQJwFsd48Hs2WXMbMDZrbHzPYUOrur2JzI6ldNoF4EcC3Ja0i2A7gbwLMxuyVSn676bygzK5L8LIAfAmgF8C0zezVsz0TqUDWdEjCz7wP4ftC+iNQ9XSkhEkiBEgmkQIkEUqBEAilQIoEUKJFACpRIIAVKJJACJRJIgRIJpECJBFKgRAIpUCKBFCiRQAqUSCAFSiSQAiUSSIESCaRAiQRSoEQCKVAigRYNFMlvkRwm+Uu3rI/k8yRfz35uWN7dFKkPeY5Q/wpgf8WyhwC8YGbXAngheyzS9BYNlJn9BMDZisV3Angsaz8G4OOxuyVSn672b6h+MzuVtd8F0B+0PyJ1repOCSvN2LbgrG2afUOaydUG6jTJrQCQ/RxeaEXNviHN5GoD9SyAT2ftTwP4j5jdEalvebrNvw3gvwBcT3KI5L0AvgxgH8nXAXwkeyzS9BadfcPM7lngqVuD90Wk7ulKCZFACpRIIAVKJJACJRJIgRIJpECJBFKgRAIpUCKBFCiRQAqUSCAFSiSQAiUSSIESCaRAiQRSoEQCKVAigRQokUAKlEggBUokkAIlEkiBEgmkQIkEyjMu33aSB0keJfkqyfuz5ZrSRqRCniNUEcDnzWwXgJsBfIbkLmhKG5E58kxnc8rMXsra7wE4BmAAmtJGZI4l/Q1FcgeAGwEcQs4pbTT7hjST3IEi2QPguwAeMLML/rkrTWmj2TekmeQKFMk2lML0uJl9L1uce0obkWaRp5ePAB4FcMzMvuae0pQ2IhUWnX0DwC0APgXgf0m+ki37G5SmsHkqm97mBIC7lmUPRepInulsfgqACzytKW1EHF0pIRJIgRIJpECJBFKgRAIpUCKBFCiRQAqUSCAFSiSQAiUSSIESCaRAiQTKc3GsLFHLdLo1bLaQLoOcbUvrtE6ldax1/kslOZvW4Uxa3nkuPfDvP76lNe1DcWn7LDF0hBIJpECJBFLJV4XZVGGhxZVk5r6mpt1d/1N9qTzrGUrL1wyn+mx0W/qVzLSn9TvPzTvCAIpdC91ZE6/vFyPl9tkb1tdsu/VERyiRQAqUSCCVfFVodb1502tS6TW5KX1PzXSk9XvfmL9sm+l0PXX9qW3ut7PmzGy53XbhYrk9tb4rrb8M1d/GQ2fStgZ7y+3RAVe+npz/czUjHaFEAilQIoFU8lXBmMqejvPuZG5bWl7swrz8yd9z16Vfw1RfWl4YT+/TMuPKKrfdYkdqt07n3PFF9AylknLsur5ye2Rn2s/pXrc/J2O22wjyjMvXSfLnJH+Rzb7xd9nya0geInmc5JMk25d/d0VWtzwl3xSAvWZ2A4DdAPaTvBnAVwA8bGY7AZwDcO+y7aVIncgzLp8BGM0etmX/GYC9AP4yW/4YgL8F8I34Xay94Q9ffiFcz6/TRXg9J1NvW9H1zrWNpxKo82xaZ+S6+b+zfFnY4ko132Z6G0x3pffhhlQM+JPI/nq/pZpx9cXYtvR5Z1vnvxZxw9Gr31Yjyzu2eWs2auwwgOcBvAFgxMwu/Z83hNIUN/O9VrNvSNPIFSgzmzGz3QAGAdwE4H15N6DZN6SZLKmXz8xGSB4E8CEA60kWsqPUIBqor2fLTyv/WVI511JMbd+rNrk+fTfNuvJpel2q2/Y9+LNye2v7SLn91UMfLbe73khngltTZ9tl5WXrtGtfXPw2kIX41/rbQKa7fZnn3tOVoGNb0/LuUzqxe0meXr7NJNdn7S4A+1CaxfAggE9kq2n2DRHkO0JtBfAYyVaUAviUmT1H8iiAJ0j+PYCXUZryRqSp5enl+x+UpgGtXP4mSn9PNZWi622bcb1e5z7gyqfe1EvY2pXaU7Ppn7vNdcl1dKfabnJLWmfNyXR/iO9hm+xN+1CYWrzcuqxMdeuPbU3vf3FtWp/uLVun3Pu4Ene2dneN1BVdeiQSSIESCaRr+argb68Y+MDpcnuwZ6TcPvzW75TbT7/0wfQCVzINDJwtt//8/f9dbv/zT/aW221jrvxz2/U9gf4k7+RGdxtIi7v2b01aZ6ovddv5cq7tPXcS2fXsFUbdOqO+hzAtb/bBYXSEEgmkQIkEUslXBX+dW1/neFru6rnimc5yu+u061XbkGqpv7j5SLn9uQ0nyu1/av+TtDFLr/Wlnb9ruHAhvefo9vSrnRhIdVjLhCvnXG/ezBpX27lbfwsT7hYV9/5dZ9J70t1aMratuW860BFKJJACJRJIJV8OvqTx179NbE5l2LF3+8vtmWJa3nbBfWe55ky362FzXWn/dmFTud3xjjubu4C2UVeGnUpX87denwZUaRlPG+4aTm3fszex2ZWpm9ITYx3us7jev97jqXuxcPp8Wn/btkX3uZHpCCUSSIESCdQUJZ8fEMWfUPW3LPgx7azya8b15tkCd7BOD6fRWOhur/Anfyc3uFtqO1Kp9tWf7S+3236bXrD2HTfun7ulwp88bZlO78Nianec9TN3pA/U/Y4b32/C3X3clbbbcd1EuT3R6XvtUo9l4dS59NoTb6dV/lAln4gEUaBEAjVFydcxkkqtmc70HTK1zpdyaf3KIY19ieWfm17rSsne1DM2O+Wuu3PlH9e4km8yrbPxSGqvfcv1sG1NNeVE6vxDR+pUQ7E7vXZsR7oHw8/c4a+7872UU+v8dt1neWtdubnQoAXTA2m8vvN/PLjAWs1HRyiRQAqUSKCmKPkmNs//Mf21bLP+/GvFLQj+FgZfGhbG3MAm/hZW98ZtF9K2Z90J1tnOtI4fgMXvky8v/T74wVL8ay+uTe9/MZ3XvWxyt8JkevF099V/n57fuWbxlZqQjlAigRQokUBNUfLl4Ycx9oOaABVj4rk7ZPt/nkYwOVVI4+kV0nlRrH0rlVjj/en76/zvud687Wl559n0K7nY60pBV+a1j84/np4vEX3Z2jbuTuaOpicmNurXHy33ESobjvllks9ljzX7hkiFpZR896M0wOUlmn1DpEKuYz7JQQAfA/APAB4kSTTY7BttE6mM8idFK/k5Z2HpNV07t6T3cnMi+F41f/dr4Vz6p7fW9D6TG9N3nJ+sbXbxOznQNu7b/jrAFtfuhCyfvEeorwP4AlKH7UbknH1DpJnkGdv8dgDDZnZksXUXeL2ms5GmkafkuwXAHSRvQ+n6/XUAHkHO2TfM7ACAAwDQvWn7qp2mYdadsJ3puPy5Fj/2XWeqvYrrUvnke9X85GWTG9Ib+2GN/YRls77EdGWk3+5ls2DIqrXoEcrMvmRmg2a2A8DdAH5kZp+EZt8QmaOaE7tfRKmD4jhKf1Np9g1pekudcO3HAH6ctRtq9o0rTVbmhxo+//50kZzvDfQnfPPw1+z1DKV6cbrHze7RPv/tJbJ66dIjkUAKlEggXcw1D98bV+lKJ32v1kK3l0j90RFKJJACJRJIgRIJpECJBFKgRAIpUCKBFCiRQAqUSCAFSiSQAiUSSIESCaRAiQRSoEQCKVAigRQokUAKlEggBUokkAIlEijv2Oa/AfAegBkARTPbQ7IPwJMAdgD4DYC7zOzc8uymSH1YyhHqT81st5ntyR4/BOAFM7sWwAvZY5GmVk3JdydKs24g+/nxqvdGpM7lDZQB+E+SR0jely3rN7NTWftdAP3heydSZ/KOX/VhMztJcguA50n+yj9pZkZy3okAsgDeBwDt3Ruq2lmR1S7XEcrMTmY/hwE8g9IQzKdJbgWA7OfwAq89YGZ7zGxPobM7Zq9FVqk880N1k1x7qQ3gowB+CeBZlGbdADT7hgiAfCVfP4BnSrOAogDg383sByRfBPAUyXsBnABw1/Ltpkh9WDRQ2SwbN8yz/P8A3LocOyVSr3SlhEggBUokkAIlEkiBEgmkQIkEUqBEAilQIoEUKJFACpRIIAVKJJACJRJIgRIJpECJBFKgRAIpUCKBFCiRQAqUSCAFSiSQAiUSSIESCaRAiQTKFSiS60k+TfJXJI+R/BDJPpLPk3w9+6lhYaXp5T1CPQLgB2b2PpSGFDsGzb4hMkeekWN7AfwRgEcBwMwumtkINPuGyBx5jlDXADgD4F9Ivkzym9mQzJp9Q6RCnkAVAPw+gG+Y2Y0AxlBR3pmZoTTlzRwk7yN5mOTh4uRYtfsrsqrlCdQQgCEzO5Q9fhqlgGn2DZEKiwbKzN4F8DbJ67NFtwI4Cs2+ITJH3gnXPgfgcZLtAN4E8FcohVGzb4g4uQJlZq8A2DPPU5p9Q8TRlRIigRQokUAKlEggBUokkAIlEkiBEgmkQIkEUqBEAilQIoEUKJFACpRIIAVKJJACJRJIgRIJpECJBFKgRAIpUCKBFCiRQAqUSCAFSiSQAiUSSIESCZRnsoDrSb7i/rtA8gFNZyMyV56RY18zs91mthvABwGMA3gGms5GZI6llny3AnjDzE5A09mIzLHUQN0N4NtZO9d0Npp9Q5pJ7kBl45rfAeA7lc9daTobzb4hzWQpR6g/A/CSmZ3OHueazkakmSwlUPcglXuAprMRmSPvLPDdAPYB+J5b/GUA+0i+DuAj2WORpsbSnz812hh5BqUpRX9bs42uDpvQXJ+50T/v75rZ5vmeqGmgAIDkYTObb66phtVsn7nZPq+nS49EAilQIoFWIlAHVmCbK63ZPnOzfd6ymv8NJdLIVPKJBKppoEjuJ/kayeMkG+7qdJLbSR4keZTkqyTvz5Y39K0uJFtJvkzyuezxNSQPZb/nJ7PL1ppCzQJFshXAP6J0CdMuAPeQ3FWr7ddIEcDnzWwXgJsBfCb7jI1+q8v9AI65x18B8LCZ7QRwDsC9K7JXK6CWR6ibABw3szfN7CKAJ1C6BaRhmNkpM3spa7+H0v9kA2jgW11IDgL4GIBvZo8JYC+Ap7NVGurzLqaWgRoA8LZ7PJQta0gkdwC4EcAh5LzVpU59HcAXAMxmjzcCGDGzYva4oX/PldQpsQxI9gD4LoAHzOyCf+5Kt7rUG5K3Axg2syMrvS+rRaGG2zoJYLt7PJgtaygk21AK0+Nmduli4tMkt5rZqQa71eUWAHeQvA1AJ4B1AB4BsJ5kITtKNeTveSG1PEK9CODarAeoHaW7f5+t4faXXfb3w6MAjpnZ19xTDXmri5l9ycwGzWwHSr/PH5nZJwEcBPCJbLWG+bx51CxQ2bfVZwH8EKU/1p8ys1drtf0auQXApwDsdaNE3Ybmu9XliwAeJHkcpb+pHl3h/akZXSkhEkidEiKBFCiRQAqUSCAFSiSQAiUSSIESCaRAiQRSoEQC/T+tYtHP9Lzn/gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD7CAYAAAASJLr7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQGUlEQVR4nO3da4xc9XnH8d+zV29sfAu2Y7xWTBSXCNJiwCVcqraBuKUkhbyIKDRKoxaJN0kFIlJC+qqVWil5Q8KLKhIKSalEuZQEBSGUBDlOqkqRwQZywcbFOBhsjI2xjR17L57dpy/meP7/3Z3xnvU+O+uZ+X4ktP85M3POGda/Pc+c22PuLgAxuuZ7BYB2QqCAQAQKCESggEAECghEoIBAswqUmd1kZrvMbLeZ3Re1UkCrsnM9DmVm3ZL+T9ImSfskvSDpDnffEbd6QGvpmcV7r5a02933SJKZPSbpVkkNA9UzsNB7lyyfxSKB+Xf6/SOqDJ20es/NJlBrJL2VPd4n6RNne0PvkuX6yN/dO4tFAvNvz3/e3/C5Od8pYWZ3mdk2M9s2NnRyrhcHzKvZBGq/pLXZ48Fi2gTu/qC7b3T3jd0DC2exOOD8N5tAvSBpvZldbGZ9km6X9HTMagGt6Zy/Q7l7xcy+LOknkrolfc/dXwlbM6AFzWanhNz9WUnPBq0L0PI4UwIIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCDRtoMzse2Z2yMx+m01bbmbPmdlrxc9lc7uaQGsos4X6D0k3TZp2n6TN7r5e0ubiMdDxpg2Uu/+PpCOTJt8q6eFi/LCkz8auFtCazvU71Cp3P1CM35G0Kmh9gJY2650SXu3Y1rBrG9030EnONVAHzWy1JBU/DzV6Id030EnONVBPS/piMf6ipB/FrA7Q2srsNn9U0i8lXWJm+8zsTknfkLTJzF6T9KniMdDxpu2+4e53NHjqxuB1AVoeZ0oAgQgUEIhAAYEIFBCIQAGBCBQQiEABgQgUEIhAAYEIFBCIQAGBCBQQiEABgQgUEIhAAYEIFBCIQAGBCBQQiEABgQgUEIhAAYEIFBCozH351prZFjPbYWavmNndxXRa2gCTlNlCVSR9xd0vlXSNpC+Z2aWipQ0wRZl2Ngfc/cVifELSTklrREsbYIoZfYcys3WSrpC0VSVb2tB9A52kdKDMbJGkH0i6x92P58+draUN3TfQSUoFysx6VQ3TI+7+w2Jy6ZY2QKcos5fPJD0kaae73589RUsbYJJpu29Iul7SFyT9xsxeLqb9k6otbJ4o2tvslXTbnKwh0ELKtLP5X0nW4Gla2gAZzpQAAhEoIBCBAgIRKCAQgQICESggEIECAhEoIBCBAgIRKCAQgQIClTk5FjNk42ns3fkT2bCSvabBn7V8Pvm492S69Gw8m//pxdkCstejedhCAYEIFBCIkm828ota6t4AYGLJN7YgjXt+n8YLjqQ3D1+YZjrWm17Tm92OIy8Rx/saXVkT76L7t9bGb9/7iaYtt5WwhQICESggECXfLOR73saz/5OVRWnsWUXWe6L+fMb60nj0gqx2zN97Mj2wsWz++V7EObBmy/u18elPbqiNR65KNWj/du5mdQZbKCAQgQICUfIF6TqdxvleuIYHbbPK7tTqVM6N96UnGh0gzsf5gd2og7n5geN3rltSGx+/JNWaVw7urY13bf+DmAW3gTL35VtgZs+b2a+K7hv/Uky/2My2mtluM3vczPqmmxfQ7sqUfCOSbnD3yyVtkHSTmV0j6ZuSvuXuH5V0VNKdc7aWQIsoc18+l3TmMGRv8Z9LukHS3xbTH5b0z5K+E7+KzTdy4cSjtD0nUknWeypNn1BuZePukew1Dbbb+d6/nqHs9dnB3K7T9Q/ajvfmJwXmM62/rDLy5VY+kGaar6dl67PrR5R59ZS9t3l3cdfYQ5Kek/S6pGPufuYUz32qtrip9166b6BjlAqUu4+5+wZJg5KulvSxsgug+wY6yYz28rn7MTPbIulaSUvNrKfYSg1K2j8XKzgf+g83Pj9uQgmUlVie7WHryi7NyEupP/ub7bXxfas218a3/uofauPKixfWxnkpmB/MzU04yDvDgyB5aerZv4RGexF7TqUPP7QqffiBg807n/B8V2Yv3wozW1qMByRtUrWL4RZJnyteRvcNQOW2UKslPWxm3aoG8Al3f8bMdkh6zMz+VdJLqra8ATpamb18v1a1Dejk6XtU/T7VUSaUVdl4ZGkqgSaUfNlevuOV/tp4sCed8PeXg6/Wxo8e/uP0hjfT6xvpGp32JRPWJz9YPLI8jSsD9Q8o52Vt12gq7frSKX7IcOoREIhAAYE4l28W8ks2PnLNm7XxyFh6Yu+O1bXxL39xWW3851emeuvei39aG5++PO1We3I4lX/+Xn4yXxouGLG60/O9i6cH0njoolT/9S5Nu/kqp9Ibuo+m9e8eSvPvHk7zya84zlU+UH96p2ALBQQiUEAgSr5ZyPf4Le9PJ/kt70vjN3pX1cbd76ey7e0ji2vjd9em8ZIJR3PTMC8vu/KDvPkFvtneuUpW5o18KF1bsmLwmOp5d3hx3eldY2kl8ktUFhxLC+s/mlbovcuyWrMDsYUCAhEoIBAlXwn5gdG8xBrLyqqtv1tXG69ZcSy994JUJ1VOppJv7Hg6aPv9vdfVxieG0/Se49mevfxPX1bydY/Uv2YjXzf1pte8eyBdgdv9fvr1W/YvoffD6aqAyum0DvZK2oW3eHd25cDzv0njy9Jn6URsoYBABAoI1BElnzW4ecmE8/KswViTrrr1+uPx42nv1vuL0j2X+wdSyTe0OCuxRtLCD7y6sjbOrw7uytajsjAtrHsovbd7OE2fcCOXrjS951Bat0VvZgdqs3LxvY2pjrxu7e9q418fvqg2Hh5NJd/4QPosPR8vfXlc22MLBQQiUECgjij5St0zLz8lblLJZyVufrJu/cHa+K9Xp71eD+26Ns1nJC/V0rg3K/P6j6Z5Dq3My7ms5MvOqcvXeyzrxDGhQVs2/77fp/mcWpmmL3o9/VN4/vU/0nQOfzztRqwMDJzllZ2FLRQQiEABgTqi5Bub/sLXhufEVSdkwwadL/5w2du18ZFKurvT6O50jtyCrPQaXplm1DXalY3TPHuyjhvjvdlrsgPN+T30RpZm65atc392dW1XJa9fz/3mKhWqvLrYQgGBCBQQqCNKvjImlHmT9uo1OrA7cCg9ePYXV6V5ZbcsXrg/65mblUnenxZYWZReUxlIf+NGlzVq3JuGlaxvb77XMt8T2HsiO8g7NIv7NWNapbdQxe2YXzKzZ4rHdN8AJplJyXe3qje4PIPuG8AkpUo+MxuU9GlJ/ybpXjMztVn3jXzv3fhZ/q8sejuVat2jqXwa7027/Brerjn782XD6fXjfWmeQ6uyEnEw1W1eSW/uP1x/t2XPqfxRdtvkFcrGc9yUt8OV3UJ9W9JXlXrkfVAlu28AnaTMvc0/I+mQu2+f7rUN3k87G3SMMiXf9ZJuMbObJS2QtFjSAyrZfcPdH5T0oCQNfGjtebuLacI5fpOqognnAmbl3PCy9Kb8fnT567Nb9MmyA7ID76T3ek8a5+Vm5Ui2n4cGFy1h2i2Uu3/d3QfdfZ2k2yX9zN0/L7pvAFPM5sDu11TdQbFb1e9UdN9Ax5tpw7WfS/p5MW6r7hsT9sB54+eGVmblWVYa5uXc5Ms/6snLwr4jaYFj/Vk/35N557Pp54n5x6lHQCACBQTiXL56zlJejc/BcdHRCxrUiJR5LYctFBCIQAGBCBQQiEABgQgUEIhAAYEIFBCIQAGBCBQQiEABgQgUEIhAAYEIFBCIQAGBCBQQiEABgQgUEIhAAYHK3tv8DUknJI1Jqrj7RjNbLulxSeskvSHpNnc/2mgeQCeYyRbqk+6+wd03Fo/vk7TZ3ddL2lw8BjrabEq+W1XtuqHi52dnvTZAiysbKJf0UzPbbmZ3FdNWufuBYvyOpFXhawe0mLK3EfsTd99vZislPWdmr+ZPurubTb7falURwLskqXfxslmtLHC+K7WFcvf9xc9Dkp5S9RbMB81stSQVPw81eO+D7r7R3Td2DyyMWWvgPFWmP9RCM7vgzFjSX0j6raSnVe26IdF9A5BUruRbJempahdQ9Uj6L3f/sZm9IOkJM7tT0l5Jt83dagKtYdpAFV02Lq8z/T1JN87FSgGtijMlgEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBApQJlZkvN7Ekze9XMdprZtWa23MyeM7PXip/cFhYdr+wW6gFJP3b3j6l6S7GdovsGMEWZO8cukfSnkh6SJHcfdfdjovsGMEWZLdTFkt6V9H0ze8nMvlvckpnuG8AkZQLVI+lKSd9x9yskndSk8s7dXdWWN1OY2V1mts3Mto0NnZzt+gLntTKB2idpn7tvLR4/qWrA6L4BTDJtoNz9HUlvmdklxaQbJe0Q3TeAKco2XPtHSY+YWZ+kPZL+XtUw0n0DyJQKlLu/LGljnafovgFkOFMCCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBABAoIRKCAQAQKCESggEAECghEoIBAZZoFXGJmL2f/HTeze2hnA0xV5s6xu9x9g7tvkHSVpFOSnhLtbIApZlry3SjpdXffK9rZAFPMNFC3S3q0GJdqZ0P3DXSS0oEq7mt+i6T/nvzc2drZ0H0DnWQmW6i/kvSiux8sHpdqZwN0kpkE6g6lck+inQ0wRdku8AslbZL0w2zyNyRtMrPXJH2qeAx0NKt+/WnSwszeVbWl6OGmLfT8cKE66zO3++f9sLuvqPdEUwMlSWa2zd3r9ZpqW532mTvt8+Y49QgIRKCAQPMRqAfnYZnzrdM+c6d93pqmf4cC2hklHxCoqYEys5vMbJeZ7Taztjs73czWmtkWM9thZq+Y2d3F9La+1MXMus3sJTN7pnh8sZltLX7PjxenrXWEpgXKzLol/buqpzBdKukOM7u0Wctvkoqkr7j7pZKukfSl4jO2+6Uud0vamT3+pqRvuftHJR2VdOe8rNU8aOYW6mpJu919j7uPSnpM1UtA2oa7H3D3F4vxCVX/ka1RG1/qYmaDkj4t6bvFY5N0g6Qni5e01eedTjMDtUbSW9njfcW0tmRm6yRdIWmrSl7q0qK+LemrksaLxx+UdMzdK8Xjtv49T8ZOiTlgZosk/UDSPe5+PH/ubJe6tBoz+4ykQ+6+fb7X5XzR08Rl7Ze0Nns8WExrK2bWq2qYHnH3MycTHzSz1e5+oM0udble0i1mdrOkBZIWS3pA0lIz6ym2Um35e26kmVuoFyStL/YA9al69e/TTVz+nCu+Pzwkaae735891ZaXurj719190N3Xqfr7/Jm7f17SFkmfK17WNp+3jKYFqvhr9WVJP1H1y/oT7v5Ks5bfJNdL+oKkG7K7RN2szrvU5WuS7jWz3ap+p3pontenaThTAgjETgkgEIECAhEoIBCBAgIRKCAQgQICESggEIECAv0/ZSeeLSlQbUUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory_batch: 11\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02084592d0>, 44, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 705.6795\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9788\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 225.8271\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9785\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 98.3276\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9783\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 24.1221\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9782\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 6.7112\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9780\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.2762\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.3741\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.4370\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.1518\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.2758\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.3507\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.1221\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.2049\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 7.1652\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 7.8441\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.3120\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 7.1935\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.3867\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.0491\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.5264\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4817\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2124\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1524\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0934\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0830\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0875\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1155\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1069\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0771\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4288\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0208\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0384\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0414\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0169\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0022\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0031\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9771\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9773\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9774\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9776\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9777\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9778\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0000\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9779\n",
      "Validation acc: 0.4814\n",
      "Memory_batch: 12\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f02dc30f210>, 42, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1278.5367\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9775\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 709.1785\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9772\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 354.8216\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 62.1822\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 22.1988\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 14.0099\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 9.0791\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 6.5096\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.0549\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.8453\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.0681\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.9693\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.6532\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4304\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3646\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0524\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1911\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0035\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4809\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0035\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0052\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0076\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0062\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4810\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0039\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0039\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4811\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0037\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0035\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4812\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0034\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0032\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0030\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4813\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0028\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0026\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0024\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4814\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0023\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0022\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0021\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4815\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0020\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0019\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0018\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4816\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4817\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0016\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4818\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4819\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4820\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4821\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4822\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4823\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0013\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4824\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4825\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4826\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0012\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4827\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4828\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4829\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4830\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4831\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4832\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4833\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0010\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4833\n",
      "Memory_batch: 13\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f029c7a0510>, 43, 0]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 574.7928\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 57.2781\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4834\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 34.4127\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 17.3997\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.7105\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 5.6136\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.9124\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.0701\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4835\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.9194\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.3286\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4836\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.7333\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 3.1974\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4837\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4457\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2162\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4838\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1738\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1391\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4839\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1055\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2609\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0747\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4840\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0646\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4841\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0570\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4841\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0532\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4841\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0495\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4842\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0494\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4842\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0494\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4843\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0493\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4843\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0490\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4844\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0483\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4844\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0477\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4845\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0465\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4845\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0451\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4846\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0435\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4846\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0420\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4847\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0403\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4847\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0386\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4847\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0369\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4848\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0356\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4848\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0344\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4849\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0331\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4849\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0313\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4850\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0295\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4850\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0279\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4851\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0264\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4851\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0249\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4852\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0234\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4852\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0219\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4853\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0208\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4853\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0199\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4853\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0191\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4854\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0184\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4854\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0176\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4855\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0171\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4855\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0168\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4855\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0165\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4856\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0159\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4856\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0151\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4857\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0142\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4857\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0134\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4857\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0125\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4858\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0117\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4858\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0109\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4859\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0104\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4859\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0101\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4859\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0099\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4860\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0099\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4860\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0098\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4861\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0098\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4861\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0097\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4861\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0097\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4862\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0096\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4862\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0096\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4863\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4863\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4863\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9765\n",
      "Validation acc: 0.4864\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4864\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4865\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4865\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0094\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4865\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0094\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4866\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0094\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4866\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0094\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4866\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0093\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4866\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0093\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4867\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0093\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4867\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4867\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9767\n",
      "Validation acc: 0.4868\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0092\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4868\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4868\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4869\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0091\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4869\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4870\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9768\n",
      "Validation acc: 0.4870\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4870\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4871\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4871\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0090\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4871\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4872\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9769\n",
      "Validation acc: 0.4872\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4873\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0089\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9770\n",
      "Validation acc: 0.4873\n",
      "Memory_batch: 14\n",
      "\n",
      "[<nibabel.nifti1.Nifti1Image object at 0x7f029c254f10>, 40, 1]\n",
      "1500\n",
      "Size of x_group: 100\n",
      "Size of y_group: 100\n",
      "Size of x_val: 100\n",
      "Size of y_val: 100\n",
      "--------------Epoch 0------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 561.0820\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9766\n",
      "Validation acc: 0.4873\n",
      "--------------Epoch 1------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 303.9349\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4873\n",
      "--------------Epoch 2------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 93.9513\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4873\n",
      "--------------Epoch 3------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 19.7521\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 4------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 11.4582\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 5------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 8.0075\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 6------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 6.5729\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 7------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 2.4830\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 8------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.9210\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 9------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.4947\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 10------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.8545\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 11------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 1.0428\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 12------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.8004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 13------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.6463\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 14------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5915\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4874\n",
      "--------------Epoch 15------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5775\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4875\n",
      "--------------Epoch 16------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.5165\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4875\n",
      "--------------Epoch 17------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.4626\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4875\n",
      "--------------Epoch 18------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3733\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4875\n",
      "--------------Epoch 19------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.3015\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4875\n",
      "--------------Epoch 20------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.2406\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 21------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.1451\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 22------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0719\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 23------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0564\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 24------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0505\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 25------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0409\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 26------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0162\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4876\n",
      "--------------Epoch 27------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0080\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4877\n",
      "--------------Epoch 28------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0061\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4877\n",
      "--------------Epoch 29------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0051\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4877\n",
      "--------------Epoch 30------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0043\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9752\n",
      "Validation acc: 0.4877\n",
      "--------------Epoch 31------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0036\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4877\n",
      "--------------Epoch 32------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0030\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4878\n",
      "--------------Epoch 33------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0025\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4878\n",
      "--------------Epoch 34------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0021\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4878\n",
      "--------------Epoch 35------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0017\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9753\n",
      "Validation acc: 0.4878\n",
      "--------------Epoch 36------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0014\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4878\n",
      "--------------Epoch 37------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4879\n",
      "--------------Epoch 38------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0009\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4879\n",
      "--------------Epoch 39------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0007\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4879\n",
      "--------------Epoch 40------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4879\n",
      "--------------Epoch 41------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9754\n",
      "Validation acc: 0.4880\n",
      "--------------Epoch 42------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0005\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4880\n",
      "--------------Epoch 43------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4880\n",
      "--------------Epoch 44------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0004\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4880\n",
      "--------------Epoch 45------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4880\n",
      "--------------Epoch 46------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4881\n",
      "--------------Epoch 47------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9755\n",
      "Validation acc: 0.4881\n",
      "--------------Epoch 48------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4881\n",
      "--------------Epoch 49------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4881\n",
      "--------------Epoch 50------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 51------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 52------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 53------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9756\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 54------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4882\n",
      "--------------Epoch 55------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4883\n",
      "--------------Epoch 56------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4883\n",
      "--------------Epoch 57------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4883\n",
      "--------------Epoch 58------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4883\n",
      "--------------Epoch 59------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9757\n",
      "Validation acc: 0.4884\n",
      "--------------Epoch 60------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4884\n",
      "--------------Epoch 61------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4884\n",
      "--------------Epoch 62------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4884\n",
      "--------------Epoch 63------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4884\n",
      "--------------Epoch 64------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4885\n",
      "--------------Epoch 65------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9758\n",
      "Validation acc: 0.4885\n",
      "--------------Epoch 66------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4885\n",
      "--------------Epoch 67------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4885\n",
      "--------------Epoch 68------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4886\n",
      "--------------Epoch 69------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4886\n",
      "--------------Epoch 70------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4886\n",
      "--------------Epoch 71------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9759\n",
      "Validation acc: 0.4886\n",
      "--------------Epoch 72------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4886\n",
      "--------------Epoch 73------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4887\n",
      "--------------Epoch 74------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4887\n",
      "--------------Epoch 75------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4887\n",
      "--------------Epoch 76------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4887\n",
      "--------------Epoch 77------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9760\n",
      "Validation acc: 0.4887\n",
      "--------------Epoch 78------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4888\n",
      "--------------Epoch 79------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4888\n",
      "--------------Epoch 80------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4888\n",
      "--------------Epoch 81------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4888\n",
      "--------------Epoch 82------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4888\n",
      "--------------Epoch 83------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4889\n",
      "--------------Epoch 84------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9761\n",
      "Validation acc: 0.4889\n",
      "--------------Epoch 85------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4889\n",
      "--------------Epoch 86------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4889\n",
      "--------------Epoch 87------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4890\n",
      "--------------Epoch 88------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4890\n",
      "--------------Epoch 89------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4890\n",
      "--------------Epoch 90------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9762\n",
      "Validation acc: 0.4890\n",
      "--------------Epoch 91------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4890\n",
      "--------------Epoch 92------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4891\n",
      "--------------Epoch 93------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4891\n",
      "--------------Epoch 94------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4891\n",
      "--------------Epoch 95------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4891\n",
      "--------------Epoch 96------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9763\n",
      "Validation acc: 0.4891\n",
      "--------------Epoch 97------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4892\n",
      "--------------Epoch 98------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4892\n",
      "--------------Epoch 99------------------\n",
      "0\n",
      "Training loss (for one batch) at step 0: 0.0002\n",
      "Seen so far: 100 samples\n",
      "Training acc over epoch: 0.9764\n",
      "Validation acc: 0.4892\n"
     ]
    }
   ],
   "source": [
    "# Suraj - finish this\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "MEMORY_GROUP_SIZE = 15\n",
    "\n",
    "tuples = get_training_data()\n",
    "N_TOTAL_SLICES = len(tuples)\n",
    "\n",
    "N_MEMORY_SIZE = BATCH_SIZE * MEMORY_GROUP_SIZE    # how many slices you want to load into memory at any time, like 500\n",
    "#N_MEMORY_GROUPS = N_TOTAL_SLICES // N_MEMORY_SIZE # THIS IS INTEGER FOR THE # OF GROUPS OF SLICES\n",
    "N_MEMORY_GROUPS = N_MEMORY_SIZE // BATCH_SIZE  \n",
    "                                                  # TO LOAD _AND_ DEL.\n",
    "                                                  # note in Python 3,\n",
    "                                                  #  // means give integer, not float\n",
    "\n",
    "model = define_model()   \n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = keras.metrics.BinaryAccuracy()\n",
    "val_acc_metric = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "#Setting up the tensorboard\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "\n",
    "#OUTER OUTER LOOP - JUST FOR MEMORY MANAGEMENT\n",
    "for memory_batch in range(N_MEMORY_GROUPS):\n",
    "    print('Memory_batch: '+str(memory_batch)+'\\n')\n",
    "    slices, target, val_slices, val_targets = nii_slice_addresses_to_tf_dataframe(N_MEMORY_SIZE)\n",
    "    x_group = slices[memory_batch * BATCH_SIZE : (memory_batch+1) * BATCH_SIZE]\n",
    "    y_group = target[memory_batch * BATCH_SIZE : (memory_batch+1) * BATCH_SIZE]\n",
    "\n",
    "    print(\"Size of x_group: \"+ str(len(x_group)))\n",
    "    print(\"Size of y_group: \"+ str(len(y_group)))\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_group, y_group))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "    x_val = val_slices[memory_batch * BATCH_SIZE : (memory_batch+1) * BATCH_SIZE]\n",
    "    y_val = val_targets[memory_batch * BATCH_SIZE : (memory_batch+1) * BATCH_SIZE]\n",
    "\n",
    "    print(\"Size of x_val: \"+ str(len(x_val)))\n",
    "    print(\"Size of y_val: \"+ str(len(y_val)))\n",
    " \n",
    "    # Prepare the validation dataset.\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    val_dataset = val_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "    \n",
    "    #OUTER LOOP\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('--------------Epoch '+ str(epoch) +'------------------')\n",
    "        #INNER LOOP        \n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "\n",
    "                        # Run the forward pass of the layer.\n",
    "                        # The operations that the layer applies\n",
    "                        # to its inputs are going to be recorded\n",
    "                        # on the GradientTape.\n",
    "                logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "\n",
    "                        # Compute the loss value for this minibatch.\n",
    "                y_batch_train = np.reshape([y_batch_train], (len(y_batch_train), 1))                        \n",
    "                loss_value = loss_fn(y_batch_train, logits)\n",
    "\n",
    "                    # Use the gradient tape to automatically retrieve\n",
    "                    # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "                    # Run one step of gradient descent by updating\n",
    "                    # the value of the variables to minimize the loss.\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "            train_acc_metric.update_state(y_batch_train, logits)\n",
    "            \n",
    "            # # %%\n",
    "            # if epoch % 100 == 0:\n",
    "            #     img = slices[0]\n",
    "            #     for i in range(7):\n",
    "            #         plt.imshow(img[:,:,i])\n",
    "            #         plt.show()\n",
    "                \n",
    "        \n",
    "\n",
    "                    # Log every 200 batches.\n",
    "\n",
    "            print(step)    \n",
    "            if step % 100 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                    % (step, float(loss_value))\n",
    "                )\n",
    "                print(\"Seen so far: %s samples\" % ((step + 1) * BATCH_SIZE))\n",
    "        \n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.scalar('accuracy', train_acc, step=epoch)\n",
    "                # Run a validation loop at the end of each epoch.\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            val_logits = model(x_batch_val, training=True) #False)\n",
    "            # Update val metrics\n",
    "            val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "        val_acc = val_acc_metric.result()\n",
    "        #val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        tf.summary.scalar('val_accuracy', val_acc, step=epoch)\n",
    "\n",
    "        \n",
    "    # %%\n",
    "    if memory_batch % 5 == 0:\n",
    "        img = slices[0]\n",
    "        for i in range(7):\n",
    "            plt.imshow(img[:,:,i])\n",
    "            plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02d8e286d12723e6538730b54a0042cc3829196cbfa1e049b88390ef3b0117a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
